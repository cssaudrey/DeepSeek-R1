{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unsloth 加速\n",
        "#### 使 Llama-3、Mistral、Phi-4 和 Gemma 等大型语言模型的微调速度提高了 2 倍，使用的内存减少了 70%，并且准确性没有下降！\n",
        "\n",
        "DeepSeek 开发了 GRPO （Group Relative Policy Optimization） 来训练他们的 R1 推理模型。这种 RL 技术无需价值函数模型即可有效地优化响应，与 PPO （近端策略优化） 相比，减少了内存和计算成本。\n",
        "\n",
        "建议将 GRPO 应用于参数至少为 1.5B 的模型，以正确生成思维标记，因为较小的模型可能无法正确生成。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xX0S9_4PwBg"
      },
      "source": [
        "###  Installation dependence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DQjPAnTFPwBg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unsloth in /anaconda/envs/sglang/lib/python3.12/site-packages (2025.2.12)\n",
            "Requirement already satisfied: vllm in /anaconda/envs/sglang/lib/python3.12/site-packages (0.7.2)\n",
            "Requirement already satisfied: psutil in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (7.0.0)\n",
            "Requirement already satisfied: sentencepiece in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (1.0.4)\n",
            "Requirement already satisfied: py-cpuinfo in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.48.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (4.48.3)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.21.0)\n",
            "Requirement already satisfied: protobuf in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (3.20.3)\n",
            "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.115.8)\n",
            "Requirement already satisfied: aiohttp in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (3.11.12)\n",
            "Requirement already satisfied: openai>=1.52.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (1.63.0)\n",
            "Requirement already satisfied: uvicorn[standard] in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.34.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (2.10.6)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (11.1.0)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (7.0.2)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.9.0)\n",
            "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.10.10)\n",
            "Requirement already satisfied: outlines==0.1.11 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.1.11)\n",
            "Requirement already satisfied: lark==1.2.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (1.2.2)\n",
            "Requirement already satisfied: xgrammar>=0.1.6 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.1.13)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (4.12.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (3.17.0)\n",
            "Requirement already satisfied: partial-json-parser in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.2.1.1.post5)\n",
            "Requirement already satisfied: pyzmq in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (26.2.1)\n",
            "Requirement already satisfied: msgspec in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.19.0)\n",
            "Requirement already satisfied: gguf==0.10.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.10.0)\n",
            "Requirement already satisfied: importlib_metadata in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (8.6.1)\n",
            "Requirement already satisfied: mistral_common>=1.5.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from mistral_common[opencv]>=1.5.0->vllm) (1.5.3)\n",
            "Requirement already satisfied: pyyaml in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (1.17.0)\n",
            "Requirement already satisfied: setuptools>=74.1.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (75.8.0)\n",
            "Requirement already satisfied: einops in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.9.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.9.1)\n",
            "Requirement already satisfied: depyf==0.18.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.18.0)\n",
            "Requirement already satisfied: cloudpickle in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (3.1.1)\n",
            "Requirement already satisfied: ray>=2.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (2.42.1)\n",
            "Requirement already satisfied: nvidia-ml-py>=12.560.30 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (12.570.86)\n",
            "Requirement already satisfied: torch==2.5.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (2.5.1)\n",
            "Requirement already satisfied: torchaudio==2.5.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (2.5.1)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.20.1)\n",
            "Requirement already satisfied: xformers==0.0.28.post3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.0.28.post3)\n",
            "Requirement already satisfied: astor in /anaconda/envs/sglang/lib/python3.12/site-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
            "Requirement already satisfied: dill in /anaconda/envs/sglang/lib/python3.12/site-packages (from depyf==0.18.0->vllm) (0.3.8)\n",
            "Requirement already satisfied: interegular in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
            "Requirement already satisfied: jinja2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (3.1.5)\n",
            "Requirement already satisfied: nest_asyncio in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Requirement already satisfied: diskcache in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
            "Requirement already satisfied: referencing in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Requirement already satisfied: pycountry in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
            "Requirement already satisfied: airportsdata in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (20241001)\n",
            "Requirement already satisfied: outlines_core==0.1.26 in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
            "Requirement already satisfied: networkx in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm) (0.45.3)\n",
            "Requirement already satisfied: packaging in /anaconda/envs/sglang/lib/python3.12/site-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (24.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from mistral_common[opencv]>=1.5.0->vllm) (4.11.0.86)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /anaconda/envs/sglang/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pydantic>=2.9->vllm) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.5.0)\n",
            "Requirement already satisfied: aiohttp-cors in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: colorful in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (0.5.6)\n",
            "Requirement already satisfied: opencensus in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (0.11.4)\n",
            "Requirement already satisfied: smart-open in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (7.1.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (20.29.2)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (1.70.0)\n",
            "Requirement already satisfied: py-spy>=0.4.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->vllm) (2.4.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->vllm) (25.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->vllm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->vllm) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->vllm) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (2025.1.31)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /anaconda/envs/sglang/lib/python3.12/site-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /anaconda/envs/sglang/lib/python3.12/site-packages (from tokenizers>=0.19.1->vllm) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from transformers>=4.48.2->vllm) (0.5.2)\n",
            "Requirement already satisfied: pybind11 in /anaconda/envs/sglang/lib/python3.12/site-packages (from xgrammar>=0.1.6->vllm) (2.13.6)\n",
            "Requirement already satisfied: pytest in /anaconda/envs/sglang/lib/python3.12/site-packages (from xgrammar>=0.1.6->vllm) (8.3.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /anaconda/envs/sglang/lib/python3.12/site-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Requirement already satisfied: h11>=0.8 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (15.0)\n",
            "Requirement already satisfied: httpcore==1.* in /anaconda/envs/sglang/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>=1.52.0->vllm) (1.0.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/sglang/lib/python3.12/site-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from jsonschema->outlines==0.1.11->vllm) (0.22.3)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /anaconda/envs/sglang/lib/python3.12/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (0.3.9)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (4.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from opencensus->ray[default]>=2.9->vllm) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from opencensus->ray[default]>=2.9->vllm) (2.24.1)\n",
            "Requirement already satisfied: iniconfig in /anaconda/envs/sglang/lib/python3.12/site-packages (from pytest->xgrammar>=0.1.6->vllm) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pytest->xgrammar>=0.1.6->vllm) (1.5.0)\n",
            "Requirement already satisfied: wrapt in /anaconda/envs/sglang/lib/python3.12/site-packages (from smart-open->ray[default]>=2.9->vllm) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.67.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.26.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (2.38.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.6.1)\n",
            "Requirement already satisfied: pillow in /anaconda/envs/sglang/lib/python3.12/site-packages (11.1.0)\n",
            "Requirement already satisfied: diffusers in /anaconda/envs/sglang/lib/python3.12/site-packages (0.32.2)\n",
            "Requirement already satisfied: importlib-metadata in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (0.28.1)\n",
            "Requirement already satisfied: numpy in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (0.5.2)\n",
            "Requirement already satisfied: Pillow in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.23.2->diffusers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /anaconda/envs/sglang/lib/python3.12/site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests->diffusers) (2025.1.31)\n",
            "Collecting git+https://github.com/huggingface/trl.git@e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
            "  Cloning https://github.com/huggingface/trl.git (to revision e95f9fb74a3c3647b86f251b7e230ec51c64b72b) to /tmp/pip-req-build-0f3gl1by\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-0f3gl1by\n",
            "  Running command git rev-parse -q --verify 'sha^e95f9fb74a3c3647b86f251b7e230ec51c64b72b'\n",
            "  Running command git fetch -q https://github.com/huggingface/trl.git e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
            "  Running command git checkout -q e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
            "  Resolved https://github.com/huggingface/trl.git to commit e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.34.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from trl==0.15.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: datasets>=2.21.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from trl==0.15.0.dev0) (3.3.0)\n",
            "Requirement already satisfied: rich in /anaconda/envs/sglang/lib/python3.12/site-packages (from trl==0.15.0.dev0) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from trl==0.15.0.dev0) (4.48.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (24.2)\n",
            "Requirement already satisfied: psutil in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (2.5.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (19.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl==0.15.0.dev0) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (3.11.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from transformers>=4.46.0->trl==0.15.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /anaconda/envs/sglang/lib/python3.12/site-packages (from transformers>=4.46.0->trl==0.15.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from rich->trl==0.15.0.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from rich->trl==0.15.0.dev0) (2.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl==0.15.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->trl==0.15.0.dev0) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (75.8.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pandas->datasets>=2.21.0->trl==0.15.0.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pandas->datasets>=2.21.0->trl==0.15.0.dev0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pandas->datasets>=2.21.0->trl==0.15.0.dev0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl==0.15.0.dev0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.0.2)\n",
            "Building wheels for collected packages: trl\n",
            "  Building wheel for trl (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for trl: filename=trl-0.15.0.dev0-py3-none-any.whl size=314513 sha256=c753e3b67e0a6e188690a00bcfc03c784634e3f6e66a19a01699e4b1614ba51c\n",
            "  Stored in directory: /home/olivia/.cache/pip/wheels/1f/46/e2/1d706f988ec4990b7054b69e1191b11d7f48a1b5304605bf21\n",
            "Successfully built trl\n",
            "Installing collected packages: trl\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.15.0\n",
            "    Uninstalling trl-0.15.0:\n",
            "      Successfully uninstalled trl-0.15.0\n",
            "Successfully installed trl-0.15.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install unsloth vllm\n",
        "!pip install --upgrade pillow\n",
        "!pip install diffusers\n",
        "# Temporarily install a specific TRL nightly version\n",
        "!pip install git+https://github.com/huggingface/trl.git@e95f9fb74a3c3647b86f251b7e230ec51c64b72b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZIDvOXePwBh"
      },
      "source": [
        "### install Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaBUw4wJ2WlP"
      },
      "source": [
        "使用PatchFastRL对HuggingFace的trl进行修改，注入自己的加速代码。目前只支持单机版的加速。分布式版尚未支持。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59DIs5BMcvjN",
        "outputId": "5d03d8e6-d961-4101-8cd5-669944f91a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/sglang/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 02-26 07:17:24 __init__.py:190] Automatically detected platform cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-26 07:17:25,101\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel, PatchFastRL\n",
        "# Use `PatchFastRL` before all functions to patch GRPO and other RL algorithms!\n",
        "PatchFastRL(\"GRPO\", FastLanguageModel) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KROEggs82dUA"
      },
      "source": [
        "Load the phi-4 model and its tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805,
          "referenced_widgets": [
            "f57d844b2efa469e8aadd48175ce70ab",
            "47d2fd7f76754d9fa156576bc0c58abb",
            "81a0791760de4dcebd543c40d2c1e322",
            "a729c5fc5c764c85885cac7a2d4d95d0",
            "d6d5a7d96a034247b38d25d8a9cc979c",
            "4c9248100f89400d9e1407dbb168d5d6",
            "96cea0d773c8426b8be72dd7f72e5a82",
            "1b9f8a2a793640d689abc10f5f39c54b",
            "627f68389cf64e2a915a72ab147ee8a7",
            "9eed940f3815428583b4ddefc1a81469",
            "0b9230e976b34a9ea85978cf22857012",
            "22e0933485c14d94b0c1cfe198d6758f",
            "43462d5de24b4e55871b3f579798b374",
            "99577e7cbed74c89afb3d44d4fd956c5",
            "d034c840e7f74177a7b07a188d666b8d",
            "0f8ead1775934dc3a10533b67b3dd905",
            "e43ad27d5d304d1ebf9b374016409a97",
            "51948945111f437c9ed6ccab22072dd3",
            "4089236deafd4fa2be86d8dc0a29d469",
            "78cc90a50c0c4636b0f41436a820ecd3",
            "129dc789722b43439574390bba63b36a",
            "8991360910ef417db03499f76f5fe323"
          ]
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "c5a32856-2166-4485-fdb3-16241d0e6316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Switching from Unsloth dynamic quant to normal quant since\n",
            "we do not yet support fast inference for unsloth/phi-4-unsloth-bnb-4bit\n",
            "==((====))==  Unsloth 2025.2.12: Fast Llama patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    GPU: NVIDIA A100 80GB PCIe. Max memory: 79.151 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/phi-4-bnb-4bit with actual GPU utilization = 35.96%\n",
            "Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 79.15 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 512. Num Sequences = 288.\n",
            "Unsloth: vLLM's KV Cache can use up to 18.49 GB. Also swap space = 6 GB.\n",
            "INFO 02-26 07:18:11 config.py:542] This model supports multiple tasks: {'generate', 'reward', 'score', 'classify', 'embed'}. Defaulting to 'generate'.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection'], 'llm_int8_threshold': 6.0}\n",
            "INFO 02-26 07:18:12 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='unsloth/phi-4-bnb-4bit', speculative_config=None, tokenizer='unsloth/phi-4-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=512, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/phi-4-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":288}, use_cached_outputs=False, \n",
            "INFO 02-26 07:18:14 cuda.py:230] Using Flash Attention backend.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W226 07:18:14.952978546 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-26 07:18:14 model_runner.py:1110] Starting to load model unsloth/phi-4-bnb-4bit...\n",
            "INFO 02-26 07:18:16 loader.py:1102] Loading weights with BitsAndBytes quantization.  May take a while ...\n",
            "INFO 02-26 07:18:16 weight_utils.py:252] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:  50% Completed | 1/2 [02:54<02:54, 174.47s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [05:53<00:00, 177.23s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [05:53<00:00, 176.81s/it]\n",
            "\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:02<00:02,  2.64s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.08s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.02s/it]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-26 07:24:17 model_runner.py:1115] Loading model weights took 8.4920 GB\n",
            "INFO 02-26 07:24:17 punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 02-26 07:24:29 worker.py:267] Memory profiling takes 12.20 seconds\n",
            "INFO 02-26 07:24:29 worker.py:267] the current vLLM instance can use total_gpu_memory (79.15GiB) x gpu_memory_utilization (0.36) = 28.46GiB\n",
            "INFO 02-26 07:24:29 worker.py:267] model weights take 8.49GiB; non_torch_memory takes 13.01GiB; PyTorch activation peak memory takes 1.04GiB; the rest of the memory reserved for KV Cache is 5.92GiB.\n",
            "INFO 02-26 07:24:29 executor_base.py:110] # CUDA blocks: 1939, # CPU blocks: 1966\n",
            "INFO 02-26 07:24:29 executor_base.py:115] Maximum concurrency for 512 tokens per request: 60.59x\n",
            "INFO 02-26 07:24:35 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|██████████| 39/39 [00:41<00:00,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-26 07:25:17 model_runner.py:1562] Graph capturing finished in 41 secs, took 6.36 GiB\n",
            "INFO 02-26 07:25:17 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 60.18 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Not an error, but Unsloth cannot patch Attention layers with our manual autograd engine since either LoRA adapters\n",
            "are not enabled or a bias term (like in Qwen) is used.\n",
            "Not an error, but Unsloth cannot patch O projection layer with our manual autograd engine since either LoRA adapters\n",
            "are not enabled or a bias term (like in Qwen) is used.\n",
            "Unsloth 2025.2.12 patched 40 layers with 0 QKV layers, 0 O layers and 40 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import is_bfloat16_supported\n",
        "import torch\n",
        "max_seq_length = 512 # Can increase for longer reasoning traces\n",
        "lora_rank = 16 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"microsoft/phi-4\", # Load up `Phi-4 14B`, and set parameters\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.4, # Reduce if out of memory  #0.7\n",
        "    device_map='cuda:0',\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"gate_proj\", \"up_proj\", \"down_proj\",], #要微调的模块（默认包括 ）\n",
        "    lora_alpha = lora_rank,\n",
        "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSlkA49z2xZB"
      },
      "source": [
        "### 奖励函数定义和数据准备 \n",
        "<a name=\"Data\"></a\n",
        "\n",
        "可能需要等待 150 到 200 个步骤奖励才会真正增加。为了获得不错的结果，您可能需要交易至少 12 小时（这就是 GRPO 的运作方式），这不是强制性的。\n",
        "\n",
        "\n",
        "为了获得最佳结果，至少要有 500 行数据。可以尝试使用 10 行数据，但最好有更多数据。\n",
        "\n",
        "\n",
        "每次训练运行总是不同的，具体取决于模型、数据、奖励函数/验证器等。\n",
        "\n",
        "\n",
        "为了达到演示效果，参考 [@willccbb](https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXk993X6C2ZZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Load and prep dataset\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "<reasoning>\n",
        "{reasoning}\n",
        "</reasoning>\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    # 将输入的文本字符串按照\"<answer>\"进行分割，得到一个列表\n",
        "    # 取列表中的最后一个元素，即包含答案的部分\n",
        "    answer = text.split(\"<answer>\")[-1]\n",
        "    answer = answer.split(\"</answer>\")[0]\n",
        "    # 使用strip()方法去除答案字符串两端的空白字符（包括空格、换行符等）\n",
        "    # 返回处理后的答案字符串\n",
        "    return answer.strip()\n",
        "\n",
        "def extract_hash_answer(text: str) -> str | None:\n",
        "    if \"####\" not in text:\n",
        "        return None\n",
        "    return text.split(\"####\")[1].strip()\n",
        "\n",
        "# uncomment middle messages for 1-shot prompting\n",
        "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
        "    # 加载GSM8K数据集，指定split为\"train\"或\"test\"\n",
        "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
        "    # 使用map函数对数据集进行转换，将每个样本的'question'和'answer'字段转换为特定格式\n",
        "    data = data.map(lambda x: { # type: ignore\n",
        "        'prompt': [ # 构造对话提示，包含系统提示和用户问题\n",
        "            {'role': 'system', 'content': SYSTEM_PROMPT}, # 系统提示，通常包含对话的背景信息或规则\n",
        "            {'role': 'user', 'content': x['question']} # 用户问题，从原始数据中提取\n",
        "        ],\n",
        "        'answer': extract_hash_answer(x['answer']) # 提取答案的哈希值，具体实现见extract_hash_answer函数\n",
        "    }) # type: ignore\n",
        "    return data # type: ignore\n",
        "\n",
        "dataset = get_gsm8k_questions()\n",
        "\n",
        "\n",
        "############  奖励函数 ############\n",
        "\n",
        "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    # 从completions列表中提取每个完成内容的第一个元素的content部分\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    # 从prompts列表中提取最后一个元素的content部分，作为问题\n",
        "    q = prompts[0][-1]['content']\n",
        "    # 对每个响应内容调用extract_xml_answer函数，提取出答案部分\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    # 打印分隔线、问题、标准答案、第一个响应内容和第一个提取的答案\n",
        "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
        "    # 比较提取的答案与标准答案，如果相同则返回2.0，否则返回0.0，形成列表返回\n",
        "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
        "\n",
        "def int_reward_func(completions, **kwargs) -> list[float]:\n",
        "    # 从输入的completions列表中提取每个完成项的第一个内容的文本部分\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    # 对每个响应文本调用extract_xml_answer函数，提取出XML格式的答案\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    # 对每个提取出的答案进行判断，如果是数字则返回0.5，否则返回0.0\n",
        "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
        "\n",
        "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    # 定义一个正则表达式模式，用于匹配特定格式的字符串\n",
        "    # 该模式要求字符串以\"<reasoning>\"开始，然后是任意字符，接着是\"</reasoning>\"\n",
        "    # 然后是\"<answer>\"，再接着是任意字符，最后是\"</answer>\"\n",
        "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
        "    # 从输入的completions列表中提取每个完成的内容\n",
        "    # completions是一个列表，每个元素是一个字典，字典中包含一个键为\"content\"的项，其值为完成的内容\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    # 使用正则表达式模式匹配每个响应内容\n",
        "    # re.match函数尝试从字符串的开始位置匹配正则表达式\n",
        "    # 如果匹配成功，返回一个匹配对象；否则返回None\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    # 根据匹配结果生成奖励值列表\n",
        "    # 如果匹配成功（match不为None），则奖励值为0.5；否则为0.0\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def count_xml(text) -> float:\n",
        "    count = 0.0\n",
        "    if text.count(\"<reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n<answer>\\n\") == 1:\n",
        "        count += 0.125\n",
        "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
        "    if text.count(\"\\n</answer>\") == 1:\n",
        "        count += 0.125\n",
        "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
        "    return count\n",
        "\n",
        "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
        "    contents = [completion[0][\"content\"] for completion in completions]\n",
        "    return [count_xml(c) for c in contents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tze5NF5523DB"
      },
      "source": [
        "### 训练模型 Train the model\n",
        "\n",
        "和用Hugging face的trl是一样的。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptqkXK2D4d6p",
        "outputId": "344b54e8-5a9c-4676-bfc0-23f8b5cb7426"
      },
      "outputs": [],
      "source": [
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    use_vllm = True, # use vLLM for fast inference!\n",
        "    learning_rate = 5e-5,#-6\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2 = 0.99,\n",
        "    weight_decay = 0.1,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    optim = \"paged_adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    bf16 = is_bfloat16_supported(),\n",
        "    fp16 = not is_bfloat16_supported(),\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 6, # Decrease if out of memory\n",
        "    max_prompt_length = 256,\n",
        "    max_completion_length = 200,\n",
        "    max_steps = 10,# 100\n",
        "    save_steps = 250,\n",
        "    max_grad_norm = 0.1,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "前 100 个步骤可能会获得 0 奖励"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vzOuSVCL_GA9",
        "outputId": "0fe20ec2-ea69-486a-e2df-4685bd390413"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 7,473 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 1\n",
            "\\        /    Total batch size = 1 | Total steps = 10\n",
            " \"-____-\"     Number of trainable parameters = 44,236,800\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------- Question:\n",
            "A concert ticket costs $40. Mr. Benson bought 12 tickets and received a 5% discount for every ticket bought that exceeds 10. How much did Mr. Benson pay in all? \n",
            "Answer:\n",
            "476 \n",
            "Response:\n",
            "<reasoning>\n",
            "To determine how much Mr. Benson paid, we need to calculate the cost of the first 10 tickets and then apply the discount for the remaining 2 tickets.\n",
            "\n",
            "1. **Calculate the cost of the first 10 tickets:**\n",
            "   - Each ticket costs $40.\n",
            "   - Therefore, the cost for 10 tickets is \\(10 \\times 40 = 400\\) dollars.\n",
            "\n",
            "2. **Calculate the cost of the additional 2 tickets with a discount:**\n",
            "   - Normally, each ticket costs $40.\n",
            "   - He receives a 5% discount for each ticket beyond the 10th.\n",
            "   - The discount per ticket is \\(5\\% \\times 40 = 0.05 \\times 40 = 2\\) dollars.\n",
            "   - Therefore, the discounted price per ticket is \\(40 - 2 = 38\\) dollars.\n",
            "   - The cost for 2 discounted tickets is \\(2 \\times 38 = 76\\) dollars.\n",
            "\n",
            " \n",
            "Extracted:\n",
            "<reasoning>\n",
            "To determine how much Mr. Benson paid, we need to calculate the cost of the first 10 tickets and then apply the discount for the remaining 2 tickets.\n",
            "\n",
            "1. **Calculate the cost of the first 10 tickets:**\n",
            "   - Each ticket costs $40.\n",
            "   - Therefore, the cost for 10 tickets is \\(10 \\times 40 = 400\\) dollars.\n",
            "\n",
            "2. **Calculate the cost of the additional 2 tickets with a discount:**\n",
            "   - Normally, each ticket costs $40.\n",
            "   - He receives a 5% discount for each ticket beyond the 10th.\n",
            "   - The discount per ticket is \\(5\\% \\times 40 = 0.05 \\times 40 = 2\\) dollars.\n",
            "   - Therefore, the discounted price per ticket is \\(40 - 2 = 38\\) dollars.\n",
            "   - The cost for 2 discounted tickets is \\(2 \\times 38 = 76\\) dollars.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 07:39, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completion_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / xmlcount_reward_func</th>\n",
              "      <th>rewards / soft_format_reward_func</th>\n",
              "      <th>rewards / strict_format_reward_func</th>\n",
              "      <th>rewards / int_reward_func</th>\n",
              "      <th>rewards / correctness_reward_func</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.064550</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.128500</td>\n",
              "      <td>0.147544</td>\n",
              "      <td>195.833344</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>-0.128500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.503000</td>\n",
              "      <td>0.925907</td>\n",
              "      <td>195.500000</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.086333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------- Question:\n",
            "Jane is trying to decide whether to buy a house or a trailer. A house costs $480,000 and a trailer costs $120,000. Each loan will be paid in monthly installments over 20 years. How much more is the monthly payment on the house compared to the trailer? \n",
            "Answer:\n",
            "1500 \n",
            "Response:\n",
            "<reasoning>\n",
            "To determine how much more the monthly payment on the house is compared to the trailer, we need to calculate the monthly loan payments for both the house and the trailer using the formula for monthly payments on an amortizing loan:\n",
            "\n",
            "\\[\n",
            "M = P \\frac{r(1 + r)^n}{(1 + r)^n - 1}\n",
            "\\]\n",
            "\n",
            "Where:\n",
            "- \\( M \\) is the monthly payment.\n",
            "- \\( P \\) is the principal loan amount (the initial amount of the loan).\n",
            "- \\( r \\) is the monthly interest rate (annual interest rate divided by 12).\n",
            "- \\( n \\) is the number of payments (loan term in years multiplied by 12).\n",
            "\n",
            "Assumptions:\n",
            "- For this problem, we have not been provided with an interest rate. In real-world scenarios, the interest rate significantly affects the monthly payment, so we will assume a hypothetical interest rate for this calculation. A common interest rate for mortgages and similar loans might \n",
            "Extracted:\n",
            "<reasoning>\n",
            "To determine how much more the monthly payment on the house is compared to the trailer, we need to calculate the monthly loan payments for both the house and the trailer using the formula for monthly payments on an amortizing loan:\n",
            "\n",
            "\\[\n",
            "M = P \\frac{r(1 + r)^n}{(1 + r)^n - 1}\n",
            "\\]\n",
            "\n",
            "Where:\n",
            "- \\( M \\) is the monthly payment.\n",
            "- \\( P \\) is the principal loan amount (the initial amount of the loan).\n",
            "- \\( r \\) is the monthly interest rate (annual interest rate divided by 12).\n",
            "- \\( n \\) is the number of payments (loan term in years multiplied by 12).\n",
            "\n",
            "Assumptions:\n",
            "- For this problem, we have not been provided with an interest rate. In real-world scenarios, the interest rate significantly affects the monthly payment, so we will assume a hypothetical interest rate for this calculation. A common interest rate for mortgages and similar loans might\n",
            "-------------------- Question:\n",
            "Janet pays $40/hour for 3 hours per week of clarinet lessons and $28/hour for 5 hours a week of piano lessons. How much more does she spend on piano lessons than clarinet lessons in a year? \n",
            "Answer:\n",
            "1040 \n",
            "Response:\n",
            "<reasoning>\n",
            "To determine how much more Janet spends on piano lessons than clarinet lessons in a year, we need to calculate the annual expense for each and then find the difference.\n",
            "\n",
            "1. **Clarinet Lessons:**\n",
            "   - Janet pays $40 per hour.\n",
            "   - She takes 3 hours per week.\n",
            "   - Weekly cost = $40/hour * 3 hours = $120.\n",
            "   - Yearly cost = $120/week * 52 weeks = $6,240.\n",
            "\n",
            "2. **Piano Lessons:**\n",
            "   - Janet pays $28 per hour.\n",
            "   - She takes 5 hours per week.\n",
            "   - Weekly cost = $28/hour * 5 hours = $140.\n",
            "   - Yearly cost = $140/week * 52 weeks = $7,280.\n",
            "\n",
            "3. **Difference:**\n",
            "   - Difference in yearly cost = Yearly cost of piano lessons - Yearly cost of clarinet lessons.\n",
            "   - Difference = $7, \n",
            "Extracted:\n",
            "<reasoning>\n",
            "To determine how much more Janet spends on piano lessons than clarinet lessons in a year, we need to calculate the annual expense for each and then find the difference.\n",
            "\n",
            "1. **Clarinet Lessons:**\n",
            "   - Janet pays $40 per hour.\n",
            "   - She takes 3 hours per week.\n",
            "   - Weekly cost = $40/hour * 3 hours = $120.\n",
            "   - Yearly cost = $120/week * 52 weeks = $6,240.\n",
            "\n",
            "2. **Piano Lessons:**\n",
            "   - Janet pays $28 per hour.\n",
            "   - She takes 5 hours per week.\n",
            "   - Weekly cost = $28/hour * 5 hours = $140.\n",
            "   - Yearly cost = $140/week * 52 weeks = $7,280.\n",
            "\n",
            "3. **Difference:**\n",
            "   - Difference in yearly cost = Yearly cost of piano lessons - Yearly cost of clarinet lessons.\n",
            "   - Difference = $7,\n",
            "-------------------- Question:\n",
            "Sabrina is collecting herbs to make a poultice for her grandmother. She needs twice as many basil leaves as sage leaves and 5 fewer sage leaves than verbena leaves. If she needs 12 basil leaves, how many leaves total does she need? \n",
            "Answer:\n",
            "29 \n",
            "Response:\n",
            "<reasoning>\n",
            "1. Let's start by defining the variables based on the problem statement:\n",
            "   - Let \\( b \\) be the number of basil leaves needed.\n",
            "   - Let \\( s \\) be the number of sage leaves needed.\n",
            "   - Let \\( v \\) be the number of verbena leaves needed.\n",
            "\n",
            "2. From the problem, we know:\n",
            "   - Sabrina needs twice as many basil leaves as sage leaves: \\( b = 2s \\).\n",
            "   - Sabrina needs 5 fewer sage leaves than verbena leaves: \\( s = v - 5 \\).\n",
            "\n",
            "3. We are given that Sabrina needs 12 basil leaves:\n",
            "   - \\( b = 12 \\).\n",
            "\n",
            "4. Substitute \\( b = 12 \\) into the equation \\( b = 2s \\):\n",
            "   - \\( 12 = 2s \\).\n",
            "   - Divide both sides by 2 to find \\( s \\): \\( s = 6 \\).\n",
            "\n",
            "5. Now that \n",
            "Extracted:\n",
            "<reasoning>\n",
            "1. Let's start by defining the variables based on the problem statement:\n",
            "   - Let \\( b \\) be the number of basil leaves needed.\n",
            "   - Let \\( s \\) be the number of sage leaves needed.\n",
            "   - Let \\( v \\) be the number of verbena leaves needed.\n",
            "\n",
            "2. From the problem, we know:\n",
            "   - Sabrina needs twice as many basil leaves as sage leaves: \\( b = 2s \\).\n",
            "   - Sabrina needs 5 fewer sage leaves than verbena leaves: \\( s = v - 5 \\).\n",
            "\n",
            "3. We are given that Sabrina needs 12 basil leaves:\n",
            "   - \\( b = 12 \\).\n",
            "\n",
            "4. Substitute \\( b = 12 \\) into the equation \\( b = 2s \\):\n",
            "   - \\( 12 = 2s \\).\n",
            "   - Divide both sides by 2 to find \\( s \\): \\( s = 6 \\).\n",
            "\n",
            "5. Now that\n",
            "-------------------- Question:\n",
            "Over the past five years, on July 4th, the high temperature for Washington, DC has been: 90 degrees in 2020, 90 degrees in 2019, 90 degrees in 2018, 79 degrees in 2017 and 71 degrees in 2016. What is the average temperature for July 4th in Washington, DC over the past 5 years? \n",
            "Answer:\n",
            "84 \n",
            "Response:\n",
            "<reasoning>\n",
            "To find the average temperature for July 4th over the past five years, we need to sum up all the recorded high temperatures for those years and then divide by the number of years.\n",
            "\n",
            "The recorded temperatures are:\n",
            "- 2020: 90 degrees\n",
            "- 2019: 90 degrees\n",
            "- 2018: 90 degrees\n",
            "- 2017: 79 degrees\n",
            "- 2016: 71 degrees\n",
            "\n",
            "First, add the temperatures together:\n",
            "\\[ 90 + 90 + 90 + 79 + 71 = 420 \\]\n",
            "\n",
            "Next, divide the total sum by the number of years (5 years):\n",
            "\\[ \\frac{420}{5} = 84 \\]\n",
            "\n",
            "Therefore, the average temperature for July 4th over the past five years is 84 degrees.\n",
            "</reasoning>\n",
            "\n",
            "<answer>\n",
            "The average temperature for July 4th in Washington, DC over the past 5 years is 84 degrees.\n",
            "</answer> \n",
            "Extracted:\n",
            "The average temperature for July 4th in Washington, DC over the past 5 years is 84 degrees.\n",
            "-------------------- Question:\n",
            "Rene can finish reading 30 pages in 60 minutes. Lulu can read 27 pages in 60 minutes and Cherry can read 25 pages in 60 minutes. If they have been reading for 240 minutes now, how many pages have they finished reading in total? \n",
            "Answer:\n",
            "328 \n",
            "Response:\n",
            "<reasoning>\n",
            "To find out how many pages Rene, Lulu, and Cherry have finished reading in total after 240 minutes, we first need to determine how many pages each person reads per minute and then calculate how many pages they read in 240 minutes.\n",
            "\n",
            "1. Rene reads 30 pages in 60 minutes. Therefore, Rene's reading rate is:\n",
            "   \\[\n",
            "   \\frac{30 \\text{ pages}}{60 \\text{ minutes}} = 0.5 \\text{ pages per minute}\n",
            "   \\]\n",
            "   In 240 minutes, Rene reads:\n",
            "   \\[\n",
            "   0.5 \\text{ pages/minute} \\times 240 \\text{ minutes} = 120 \\text{ pages}\n",
            "   \\]\n",
            "\n",
            "2. Lulu reads 27 pages in 60 minutes. Therefore, Lulu's reading rate is:\n",
            "   \\[\n",
            "   \\frac{27 \\text{ pages}}{60 \\text{ minutes}} = 0.45 \\ \n",
            "Extracted:\n",
            "<reasoning>\n",
            "To find out how many pages Rene, Lulu, and Cherry have finished reading in total after 240 minutes, we first need to determine how many pages each person reads per minute and then calculate how many pages they read in 240 minutes.\n",
            "\n",
            "1. Rene reads 30 pages in 60 minutes. Therefore, Rene's reading rate is:\n",
            "   \\[\n",
            "   \\frac{30 \\text{ pages}}{60 \\text{ minutes}} = 0.5 \\text{ pages per minute}\n",
            "   \\]\n",
            "   In 240 minutes, Rene reads:\n",
            "   \\[\n",
            "   0.5 \\text{ pages/minute} \\times 240 \\text{ minutes} = 120 \\text{ pages}\n",
            "   \\]\n",
            "\n",
            "2. Lulu reads 27 pages in 60 minutes. Therefore, Lulu's reading rate is:\n",
            "   \\[\n",
            "   \\frac{27 \\text{ pages}}{60 \\text{ minutes}} = 0.45 \\\n",
            "-------------------- Question:\n",
            "Martin rings the small bell 4 times more than 1/3 as often as the big bell. If he rings both of them a combined total of 52 times, how many times does he ring the big bell? \n",
            "Answer:\n",
            "36 \n",
            "Response:\n",
            "<reasoning>\n",
            "Let \\( x \\) represent the number of times Martin rings the big bell. According to the problem, Martin rings the small bell 4 times more than \\(\\frac{1}{3}\\) as often as the big bell. Thus, the number of times he rings the small bell can be expressed as:\n",
            "\n",
            "\\[ \\text{Small bell rings} = \\frac{1}{3}x + 4 \\]\n",
            "\n",
            "Since Martin rings both bells a combined total of 52 times, we can set up the following equation representing the total number of rings:\n",
            "\n",
            "\\[ x + \\left(\\frac{1}{3}x + 4\\right) = 52 \\]\n",
            "\n",
            "Simplifying the equation:\n",
            "\n",
            "\\[ x + \\frac{1}{3}x + 4 = 52 \\]\n",
            "\n",
            "Combine like terms:\n",
            "\n",
            "\\[ \\frac{3}{3}x + \\frac{1}{3}x = \\frac{4}{3}x \\]\n",
            "\n",
            "So the \n",
            "Extracted:\n",
            "<reasoning>\n",
            "Let \\( x \\) represent the number of times Martin rings the big bell. According to the problem, Martin rings the small bell 4 times more than \\(\\frac{1}{3}\\) as often as the big bell. Thus, the number of times he rings the small bell can be expressed as:\n",
            "\n",
            "\\[ \\text{Small bell rings} = \\frac{1}{3}x + 4 \\]\n",
            "\n",
            "Since Martin rings both bells a combined total of 52 times, we can set up the following equation representing the total number of rings:\n",
            "\n",
            "\\[ x + \\left(\\frac{1}{3}x + 4\\right) = 52 \\]\n",
            "\n",
            "Simplifying the equation:\n",
            "\n",
            "\\[ x + \\frac{1}{3}x + 4 = 52 \\]\n",
            "\n",
            "Combine like terms:\n",
            "\n",
            "\\[ \\frac{3}{3}x + \\frac{1}{3}x = \\frac{4}{3}x \\]\n",
            "\n",
            "So the\n",
            "-------------------- Question:\n",
            "Bert fills out the daily crossword puzzle in the newspaper every day. He uses up a pencil to fill out the puzzles every two weeks. On average, it takes him 1050 words to use up a pencil. How many words are in each crossword puzzle on average? \n",
            "Answer:\n",
            "75 \n",
            "Response:\n",
            "<reasoning>\n",
            "1. Begin by understanding the problem: Bert fills out a crossword puzzle every day and uses up a pencil every two weeks. \n",
            "\n",
            "2. Calculate the number of days in two weeks:  \n",
            "   \\[\n",
            "   2 \\text{ weeks} \\times 7 \\text{ days per week} = 14 \\text{ days}\n",
            "   \\]\n",
            "\n",
            "3. Bert fills in one crossword puzzle per day, so in 14 days, he fills out 14 crossword puzzles.\n",
            "\n",
            "4. It is given that 1050 words are written with one pencil that lasts 14 days. We need to find the average number of words written in each crossword puzzle.\n",
            "\n",
            "5. Calculate the average number of words per crossword puzzle by dividing the total number of words by the total number of puzzles filled in 14 days:\n",
            "   \\[\n",
            "   \\frac{1050 \\text{ words}}{14 \\text{ puzzles}} = 75 \\text{ words per puzzle}\n",
            "   \\]\n",
            "\n",
            " \n",
            "Extracted:\n",
            "<reasoning>\n",
            "1. Begin by understanding the problem: Bert fills out a crossword puzzle every day and uses up a pencil every two weeks. \n",
            "\n",
            "2. Calculate the number of days in two weeks:  \n",
            "   \\[\n",
            "   2 \\text{ weeks} \\times 7 \\text{ days per week} = 14 \\text{ days}\n",
            "   \\]\n",
            "\n",
            "3. Bert fills in one crossword puzzle per day, so in 14 days, he fills out 14 crossword puzzles.\n",
            "\n",
            "4. It is given that 1050 words are written with one pencil that lasts 14 days. We need to find the average number of words written in each crossword puzzle.\n",
            "\n",
            "5. Calculate the average number of words per crossword puzzle by dividing the total number of words by the total number of puzzles filled in 14 days:\n",
            "   \\[\n",
            "   \\frac{1050 \\text{ words}}{14 \\text{ puzzles}} = 75 \\text{ words per puzzle}\n",
            "   \\]\n",
            "-------------------- Question:\n",
            "Matt can make a batch of a dozen cookies using 2 pounds of flour.  He uses 4 bags of flour each weighing 5 pounds.  If Jim eats 15 cookies how many cookies are left? \n",
            "Answer:\n",
            "105 \n",
            "Response:\n",
            "<reasoning>\n",
            "1. First, determine how many pounds of flour Matt has:\n",
            "   - Each bag weighs 5 pounds, and he uses 4 bags.\n",
            "   - Total flour = 4 bags × 5 pounds per bag = 20 pounds.\n",
            "\n",
            "2. Determine how many batches of cookies Matt can make with 20 pounds of flour:\n",
            "   - One batch (a dozen cookies) requires 2 pounds of flour.\n",
            "   - Number of batches = Total flour / Flour per batch = 20 pounds / 2 pounds per batch = 10 batches.\n",
            "\n",
            "3. Calculate the total number of cookies Matt can make:\n",
            "   - Each batch makes a dozen cookies = 12 cookies.\n",
            "   - Total cookies = Number of batches × Cookies per batch = 10 batches × 12 cookies per batch = 120 cookies.\n",
            "\n",
            "4. Determine how many cookies are left after Jim eats 15 cookies:\n",
            "   - Initial total cookies = 120 cookies.\n",
            "   - Cookies eaten by Jim = 15 cookies \n",
            "Extracted:\n",
            "<reasoning>\n",
            "1. First, determine how many pounds of flour Matt has:\n",
            "   - Each bag weighs 5 pounds, and he uses 4 bags.\n",
            "   - Total flour = 4 bags × 5 pounds per bag = 20 pounds.\n",
            "\n",
            "2. Determine how many batches of cookies Matt can make with 20 pounds of flour:\n",
            "   - One batch (a dozen cookies) requires 2 pounds of flour.\n",
            "   - Number of batches = Total flour / Flour per batch = 20 pounds / 2 pounds per batch = 10 batches.\n",
            "\n",
            "3. Calculate the total number of cookies Matt can make:\n",
            "   - Each batch makes a dozen cookies = 12 cookies.\n",
            "   - Total cookies = Number of batches × Cookies per batch = 10 batches × 12 cookies per batch = 120 cookies.\n",
            "\n",
            "4. Determine how many cookies are left after Jim eats 15 cookies:\n",
            "   - Initial total cookies = 120 cookies.\n",
            "   - Cookies eaten by Jim = 15 cookies\n",
            "-------------------- Question:\n",
            "James decides to build a tin house by collecting 500 tins in a week. On the first day, he collects 50 tins. On the second day, he manages to collect 3 times that number. On the third day, he collects 50 tins fewer than the number he collected on the second day. If he collects an equal number of tins on the remaining days of the week, what's the number of tins he collected each day for the rest of the week? \n",
            "Answer:\n",
            "50 \n",
            "Response:\n",
            "<reasoning>\n",
            "To determine the number of tins James collects each day for the rest of the week, we first need to calculate how many tins he has collected in the first three days of the week.\n",
            "\n",
            "1. **Day 1:** James collects 50 tins.\n",
            "   \n",
            "2. **Day 2:** He collects 3 times the number of tins collected on Day 1. Therefore, he collects \\(3 \\times 50 = 150\\) tins.\n",
            "\n",
            "3. **Day 3:** He collects 50 tins fewer than the number he collected on Day 2. Thus, he collects \\(150 - 50 = 100\\) tins.\n",
            "\n",
            "Next, we calculate the total number of tins collected over the first three days:\n",
            "\\[50 \\, (\\text{Day 1}) + 150 \\, (\\text{Day 2}) + 100 \\, (\\text{Day 3}) = 300 \\, \\text{tins \n",
            "Extracted:\n",
            "<reasoning>\n",
            "To determine the number of tins James collects each day for the rest of the week, we first need to calculate how many tins he has collected in the first three days of the week.\n",
            "\n",
            "1. **Day 1:** James collects 50 tins.\n",
            "   \n",
            "2. **Day 2:** He collects 3 times the number of tins collected on Day 1. Therefore, he collects \\(3 \\times 50 = 150\\) tins.\n",
            "\n",
            "3. **Day 3:** He collects 50 tins fewer than the number he collected on Day 2. Thus, he collects \\(150 - 50 = 100\\) tins.\n",
            "\n",
            "Next, we calculate the total number of tins collected over the first three days:\n",
            "\\[50 \\, (\\text{Day 1}) + 150 \\, (\\text{Day 2}) + 100 \\, (\\text{Day 3}) = 300 \\, \\text{tins\n"
          ]
        }
      ],
      "source": [
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [ #以上定义的多个奖励函数\n",
        "        xmlcount_reward_func,\n",
        "        soft_format_reward_func,\n",
        "        strict_format_reward_func,\n",
        "        int_reward_func,\n",
        "        correctness_reward_func,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset\n",
        ")\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 从trainer_stats对象中获取训练过程中的度量指标\n",
        "metrics = trainer_stats.metrics\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'loss': 0.0,\n",
              "  'grad_norm': 0.0,\n",
              "  'learning_rate': 5e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 0.0,\n",
              "  'epoch': 0.00013381506757660912,\n",
              "  'step': 1},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 0.08599156886339188,\n",
              "  'learning_rate': 4.849231551964771e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.0833333358168602,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.0833333358168602,\n",
              "  'reward_std': 0.06454972922801971,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 0.0,\n",
              "  'epoch': 0.00026763013515321824,\n",
              "  'step': 2},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 6.406837928807363e-05,\n",
              "  'learning_rate': 4.415111107797445e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 8.270899706985801e-05,\n",
              "  'epoch': 0.0004014452027298274,\n",
              "  'step': 3},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 7.578793884022161e-05,\n",
              "  'learning_rate': 3.7500000000000003e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 9.515773126622662e-05,\n",
              "  'epoch': 0.0005352602703064365,\n",
              "  'step': 4},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 0.028311002999544144,\n",
              "  'learning_rate': 2.9341204441673266e-05,\n",
              "  'rewards/xmlcount_reward_func': -0.12850001454353333,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': -0.12850001454353333,\n",
              "  'reward_std': 0.1475435495376587,\n",
              "  'completion_length': 195.83334350585938,\n",
              "  'kl': 8.948562754085287e-05,\n",
              "  'epoch': 0.0006690753378830456,\n",
              "  'step': 5},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 5.4759453632868826e-05,\n",
              "  'learning_rate': 2.0658795558326743e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 7.954180182423443e-05,\n",
              "  'epoch': 0.0008028904054596548,\n",
              "  'step': 6},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 7.579489465570077e-05,\n",
              "  'learning_rate': 1.2500000000000006e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 0.0001414473808836192,\n",
              "  'epoch': 0.0009367054730362638,\n",
              "  'step': 7},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 0.08122119307518005,\n",
              "  'learning_rate': 5.848888922025553e-06,\n",
              "  'rewards/xmlcount_reward_func': 0.08633333444595337,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0833333358168602,\n",
              "  'rewards/correctness_reward_func': 0.3333333432674408,\n",
              "  'reward': 0.503000020980835,\n",
              "  'reward_std': 0.9259072542190552,\n",
              "  'completion_length': 195.5,\n",
              "  'kl': 0.00022907111269887537,\n",
              "  'epoch': 0.001070520540612873,\n",
              "  'step': 8},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 5.362631782190874e-05,\n",
              "  'learning_rate': 1.5076844803522922e-06,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 0.00010956346523016691,\n",
              "  'epoch': 0.0012043356081894822,\n",
              "  'step': 9},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 0.00012698340287897736,\n",
              "  'learning_rate': 0.0,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 0.0001731372030917555,\n",
              "  'epoch': 0.0013381506757660913,\n",
              "  'step': 10},\n",
              " {'train_runtime': 515.8447,\n",
              "  'train_samples_per_second': 0.019,\n",
              "  'train_steps_per_second': 0.019,\n",
              "  'total_flos': 0.0,\n",
              "  'train_loss': 3.99779188846594e-06,\n",
              "  'epoch': 0.0013381506757660913,\n",
              "  'step': 10}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.state.log_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbdvvDCbLrLe"
      },
      "source": [
        "### 部署推理 Inference\n",
        "\n",
        "使用没GRPO训练过的模型进行推理的代码如下:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "urQZvMTaLrrQ",
        "outputId": "b2ab3c22-cfd8-43b1-b173-4b780cd3fed0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.69s/it, est. speed input: 2.47 toks/s, output: 17.57 toks/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'100以内的质数是只有1和自身两个正整数因子的自然数。它们是：\\n\\n1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97\\n\\n注意：1不是质数，它通常被排除在质数的定义之外。'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"user\", \"content\" : \"100以内的质数有哪些?\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    [text],\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100以内的质数是只有1和自身两个正整数因子的自然数。它们是：\n",
            "\n",
            "1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97\n",
            "\n",
            "注意：1不是质数，它通常被排除在质数的定义之外。\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXfSTmXFLyIE"
      },
      "source": [
        "为了使用GRPO训练后的模型，我们需要先保持训练过的LoRA权重。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XOed9DauLydR"
      },
      "outputs": [],
      "source": [
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45U-8F0nL1Uf"
      },
      "source": [
        "使用GRPO训练过的模型进行部署推理:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "__w_7GamL1m1",
        "outputId": "2402a0e9-6ec0-4f65-9921-311888040df9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:30<00:00, 30.73s/it, est. speed input: 1.66 toks/s, output: 15.03 toks/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'<reasoning>\\n要找到100以内的质数，我们首先需要了解什么是质数。质数是只能被1和它本身整除的自然数，且不等于1。因此，质数必须大于1。\\n\\n我们从2开始，因为2是最小的质数。然后，我们逐个检查每个整数是否符合质数的定义：\\n\\n- 2是质数，因为它只能被1和2整除。\\n- 3是质数，因为它只能被1和3整除。\\n- 4不是质数，因为它可以被2整除。\\n- 5是质数，因为它只能被1和5整除。\\n- 6不是质数，因为它可以被2和3整除。\\n- 7是质数，因为它只能被1和7整除。\\n- 8不是质数，因为它可以被2整除。\\n- 9不是质数，因为它可以被3整除。\\n- 10不是质数，因为它可以被2和5整除。\\n- 11是质数，因为它只能被1和11整除。\\n\\n我们继续这个过程，一直到100。在此过程中，我们需要排除所有非质数（合数），即那些能被小于自身的自然数整除的数。\\n\\n在这个范围内，可以通过除以小于其平方根的质数来测试一个数是否为质数。如果一个数不能被任何这些质数整除，那么它就是质数。\\n\\n通过这个方法，我们可以列出100以内的质数：\\n2, 3, 5,'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
        "    {\"role\" : \"user\", \"content\" : \"100以内的质数有哪些?用中文回答\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP998x4tMRFE",
        "outputId": "13ea89c4-8b26-4ee7-9fec-9ed3441eaa53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<reasoning>\n",
            "要找到100以内的质数，我们首先需要了解什么是质数。质数是只能被1和它本身整除的自然数，且不等于1。因此，质数必须大于1。\n",
            "\n",
            "我们从2开始，因为2是最小的质数。然后，我们逐个检查每个整数是否符合质数的定义：\n",
            "\n",
            "- 2是质数，因为它只能被1和2整除。\n",
            "- 3是质数，因为它只能被1和3整除。\n",
            "- 4不是质数，因为它可以被2整除。\n",
            "- 5是质数，因为它只能被1和5整除。\n",
            "- 6不是质数，因为它可以被2和3整除。\n",
            "- 7是质数，因为它只能被1和7整除。\n",
            "- 8不是质数，因为它可以被2整除。\n",
            "- 9不是质数，因为它可以被3整除。\n",
            "- 10不是质数，因为它可以被2和5整除。\n",
            "- 11是质数，因为它只能被1和11整除。\n",
            "\n",
            "我们继续这个过程，一直到100。在此过程中，我们需要排除所有非质数（合数），即那些能被小于自身的自然数整除的数。\n",
            "\n",
            "在这个范围内，可以通过除以小于其平方根的质数来测试一个数是否为质数。如果一个数不能被任何这些质数整除，那么它就是质数。\n",
            "\n",
            "通过这个方法，我们可以列出100以内的质数：\n",
            "2, 3, 5,\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "sglang",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b9230e976b34a9ea85978cf22857012": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f8ead1775934dc3a10533b67b3dd905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "129dc789722b43439574390bba63b36a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b9f8a2a793640d689abc10f5f39c54b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e0933485c14d94b0c1cfe198d6758f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43462d5de24b4e55871b3f579798b374",
              "IPY_MODEL_99577e7cbed74c89afb3d44d4fd956c5",
              "IPY_MODEL_d034c840e7f74177a7b07a188d666b8d"
            ],
            "layout": "IPY_MODEL_0f8ead1775934dc3a10533b67b3dd905"
          }
        },
        "4089236deafd4fa2be86d8dc0a29d469": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43462d5de24b4e55871b3f579798b374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e43ad27d5d304d1ebf9b374016409a97",
            "placeholder": "​",
            "style": "IPY_MODEL_51948945111f437c9ed6ccab22072dd3",
            "value": ""
          }
        },
        "47d2fd7f76754d9fa156576bc0c58abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c9248100f89400d9e1407dbb168d5d6",
            "placeholder": "​",
            "style": "IPY_MODEL_96cea0d773c8426b8be72dd7f72e5a82",
            "value": ""
          }
        },
        "4c9248100f89400d9e1407dbb168d5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51948945111f437c9ed6ccab22072dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "627f68389cf64e2a915a72ab147ee8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78cc90a50c0c4636b0f41436a820ecd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81a0791760de4dcebd543c40d2c1e322": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b9f8a2a793640d689abc10f5f39c54b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_627f68389cf64e2a915a72ab147ee8a7",
            "value": 2
          }
        },
        "8991360910ef417db03499f76f5fe323": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96cea0d773c8426b8be72dd7f72e5a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99577e7cbed74c89afb3d44d4fd956c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4089236deafd4fa2be86d8dc0a29d469",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78cc90a50c0c4636b0f41436a820ecd3",
            "value": 2
          }
        },
        "9eed940f3815428583b4ddefc1a81469": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a729c5fc5c764c85885cac7a2d4d95d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eed940f3815428583b4ddefc1a81469",
            "placeholder": "​",
            "style": "IPY_MODEL_0b9230e976b34a9ea85978cf22857012",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:51&lt;00:00, 25.46s/it]\n"
          }
        },
        "d034c840e7f74177a7b07a188d666b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_129dc789722b43439574390bba63b36a",
            "placeholder": "​",
            "style": "IPY_MODEL_8991360910ef417db03499f76f5fe323",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:47&lt;00:00, 23.63s/it]\n"
          }
        },
        "d6d5a7d96a034247b38d25d8a9cc979c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e43ad27d5d304d1ebf9b374016409a97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f57d844b2efa469e8aadd48175ce70ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47d2fd7f76754d9fa156576bc0c58abb",
              "IPY_MODEL_81a0791760de4dcebd543c40d2c1e322",
              "IPY_MODEL_a729c5fc5c764c85885cac7a2d4d95d0"
            ],
            "layout": "IPY_MODEL_d6d5a7d96a034247b38d25d8a9cc979c"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
