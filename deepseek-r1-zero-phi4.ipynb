{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unsloth åŠ é€Ÿ\n",
        "#### ä½¿ Llama-3ã€Mistralã€Phi-4 å’Œ Gemma ç­‰å¤§å‹è¯­è¨€æ¨¡å‹çš„å¾®è°ƒé€Ÿåº¦æé«˜äº† 2 å€ï¼Œä½¿ç”¨çš„å†…å­˜å‡å°‘äº† 70%ï¼Œå¹¶ä¸”å‡†ç¡®æ€§æ²¡æœ‰ä¸‹é™ï¼\n",
        "\n",
        "DeepSeek å¼€å‘äº† GRPO ï¼ˆGroup Relative Policy Optimizationï¼‰ æ¥è®­ç»ƒä»–ä»¬çš„ R1 æ¨ç†æ¨¡å‹ã€‚è¿™ç§ RL æŠ€æœ¯æ— éœ€ä»·å€¼å‡½æ•°æ¨¡å‹å³å¯æœ‰æ•ˆåœ°ä¼˜åŒ–å“åº”ï¼Œä¸ PPO ï¼ˆè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼‰ ç›¸æ¯”ï¼Œå‡å°‘äº†å†…å­˜å’Œè®¡ç®—æˆæœ¬ã€‚\n",
        "\n",
        "å»ºè®®å°† GRPO åº”ç”¨äºå‚æ•°è‡³å°‘ä¸º 1.5B çš„æ¨¡å‹ï¼Œä»¥æ­£ç¡®ç”Ÿæˆæ€ç»´æ ‡è®°ï¼Œå› ä¸ºè¾ƒå°çš„æ¨¡å‹å¯èƒ½æ— æ³•æ­£ç¡®ç”Ÿæˆã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xX0S9_4PwBg"
      },
      "source": [
        "###  Installation dependence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DQjPAnTFPwBg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unsloth in /anaconda/envs/sglang/lib/python3.12/site-packages (2025.2.12)\n",
            "Requirement already satisfied: vllm in /anaconda/envs/sglang/lib/python3.12/site-packages (0.7.2)\n",
            "Requirement already satisfied: psutil in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (7.0.0)\n",
            "Requirement already satisfied: sentencepiece in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (1.0.4)\n",
            "Requirement already satisfied: py-cpuinfo in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.48.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (4.48.3)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.21.0)\n",
            "Requirement already satisfied: protobuf in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (3.20.3)\n",
            "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.115.8)\n",
            "Requirement already satisfied: aiohttp in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (3.11.12)\n",
            "Requirement already satisfied: openai>=1.52.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (1.63.0)\n",
            "Requirement already satisfied: uvicorn[standard] in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.34.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (2.10.6)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (11.1.0)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (7.0.2)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.9.0)\n",
            "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.10.10)\n",
            "Requirement already satisfied: outlines==0.1.11 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.1.11)\n",
            "Requirement already satisfied: lark==1.2.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (1.2.2)\n",
            "Requirement already satisfied: xgrammar>=0.1.6 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.1.13)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (4.12.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (3.17.0)\n",
            "Requirement already satisfied: partial-json-parser in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.2.1.1.post5)\n",
            "Requirement already satisfied: pyzmq in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (26.2.1)\n",
            "Requirement already satisfied: msgspec in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.19.0)\n",
            "Requirement already satisfied: gguf==0.10.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.10.0)\n",
            "Requirement already satisfied: importlib_metadata in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (8.6.1)\n",
            "Requirement already satisfied: mistral_common>=1.5.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from mistral_common[opencv]>=1.5.0->vllm) (1.5.3)\n",
            "Requirement already satisfied: pyyaml in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (1.17.0)\n",
            "Requirement already satisfied: setuptools>=74.1.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (75.8.0)\n",
            "Requirement already satisfied: einops in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.9.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.9.1)\n",
            "Requirement already satisfied: depyf==0.18.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.18.0)\n",
            "Requirement already satisfied: cloudpickle in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (3.1.1)\n",
            "Requirement already satisfied: ray>=2.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (2.42.1)\n",
            "Requirement already satisfied: nvidia-ml-py>=12.560.30 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (12.570.86)\n",
            "Requirement already satisfied: torch==2.5.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (2.5.1)\n",
            "Requirement already satisfied: torchaudio==2.5.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (2.5.1)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.20.1)\n",
            "Requirement already satisfied: xformers==0.0.28.post3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from vllm) (0.0.28.post3)\n",
            "Requirement already satisfied: astor in /anaconda/envs/sglang/lib/python3.12/site-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
            "Requirement already satisfied: dill in /anaconda/envs/sglang/lib/python3.12/site-packages (from depyf==0.18.0->vllm) (0.3.8)\n",
            "Requirement already satisfied: interegular in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
            "Requirement already satisfied: jinja2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (3.1.5)\n",
            "Requirement already satisfied: nest_asyncio in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Requirement already satisfied: diskcache in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
            "Requirement already satisfied: referencing in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Requirement already satisfied: pycountry in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
            "Requirement already satisfied: airportsdata in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (20241001)\n",
            "Requirement already satisfied: outlines_core==0.1.26 in /anaconda/envs/sglang/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
            "Requirement already satisfied: networkx in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch==2.5.1->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm) (0.45.3)\n",
            "Requirement already satisfied: packaging in /anaconda/envs/sglang/lib/python3.12/site-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (24.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from mistral_common[opencv]>=1.5.0->vllm) (4.11.0.86)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /anaconda/envs/sglang/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pydantic>=2.9->vllm) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.5.0)\n",
            "Requirement already satisfied: aiohttp-cors in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: colorful in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (0.5.6)\n",
            "Requirement already satisfied: opencensus in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (0.11.4)\n",
            "Requirement already satisfied: smart-open in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (7.1.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (20.29.2)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (1.70.0)\n",
            "Requirement already satisfied: py-spy>=0.4.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from ray[default]>=2.9->vllm) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->vllm) (2.4.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->vllm) (25.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->vllm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->vllm) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->vllm) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.26.0->vllm) (2025.1.31)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /anaconda/envs/sglang/lib/python3.12/site-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /anaconda/envs/sglang/lib/python3.12/site-packages (from tokenizers>=0.19.1->vllm) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from transformers>=4.48.2->vllm) (0.5.2)\n",
            "Requirement already satisfied: pybind11 in /anaconda/envs/sglang/lib/python3.12/site-packages (from xgrammar>=0.1.6->vllm) (2.13.6)\n",
            "Requirement already satisfied: pytest in /anaconda/envs/sglang/lib/python3.12/site-packages (from xgrammar>=0.1.6->vllm) (8.3.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /anaconda/envs/sglang/lib/python3.12/site-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Requirement already satisfied: h11>=0.8 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /anaconda/envs/sglang/lib/python3.12/site-packages (from uvicorn[standard]->vllm) (15.0)\n",
            "Requirement already satisfied: httpcore==1.* in /anaconda/envs/sglang/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>=1.52.0->vllm) (1.0.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/sglang/lib/python3.12/site-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from jsonschema->outlines==0.1.11->vllm) (0.22.3)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /anaconda/envs/sglang/lib/python3.12/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (0.3.9)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (4.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from opencensus->ray[default]>=2.9->vllm) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from opencensus->ray[default]>=2.9->vllm) (2.24.1)\n",
            "Requirement already satisfied: iniconfig in /anaconda/envs/sglang/lib/python3.12/site-packages (from pytest->xgrammar>=0.1.6->vllm) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pytest->xgrammar>=0.1.6->vllm) (1.5.0)\n",
            "Requirement already satisfied: wrapt in /anaconda/envs/sglang/lib/python3.12/site-packages (from smart-open->ray[default]>=2.9->vllm) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.67.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.26.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (2.38.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/sglang/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.6.1)\n",
            "Requirement already satisfied: pillow in /anaconda/envs/sglang/lib/python3.12/site-packages (11.1.0)\n",
            "Requirement already satisfied: diffusers in /anaconda/envs/sglang/lib/python3.12/site-packages (0.32.2)\n",
            "Requirement already satisfied: importlib-metadata in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (0.28.1)\n",
            "Requirement already satisfied: numpy in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (0.5.2)\n",
            "Requirement already satisfied: Pillow in /anaconda/envs/sglang/lib/python3.12/site-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.23.2->diffusers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /anaconda/envs/sglang/lib/python3.12/site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests->diffusers) (2025.1.31)\n",
            "Collecting git+https://github.com/huggingface/trl.git@e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
            "  Cloning https://github.com/huggingface/trl.git (to revision e95f9fb74a3c3647b86f251b7e230ec51c64b72b) to /tmp/pip-req-build-0f3gl1by\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-0f3gl1by\n",
            "  Running command git rev-parse -q --verify 'sha^e95f9fb74a3c3647b86f251b7e230ec51c64b72b'\n",
            "  Running command git fetch -q https://github.com/huggingface/trl.git e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
            "  Running command git checkout -q e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
            "  Resolved https://github.com/huggingface/trl.git to commit e95f9fb74a3c3647b86f251b7e230ec51c64b72b\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.34.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from trl==0.15.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: datasets>=2.21.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from trl==0.15.0.dev0) (3.3.0)\n",
            "Requirement already satisfied: rich in /anaconda/envs/sglang/lib/python3.12/site-packages (from trl==0.15.0.dev0) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from trl==0.15.0.dev0) (4.48.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (24.2)\n",
            "Requirement already satisfied: psutil in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (2.5.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from accelerate>=0.34.0->trl==0.15.0.dev0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (19.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl==0.15.0.dev0) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /anaconda/envs/sglang/lib/python3.12/site-packages (from datasets>=2.21.0->trl==0.15.0.dev0) (3.11.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from transformers>=4.46.0->trl==0.15.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /anaconda/envs/sglang/lib/python3.12/site-packages (from transformers>=4.46.0->trl==0.15.0.dev0) (0.21.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from rich->trl==0.15.0.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from rich->trl==0.15.0.dev0) (2.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from aiohttp->datasets>=2.21.0->trl==0.15.0.dev0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl==0.15.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->trl==0.15.0.dev0) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/sglang/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.15.0.dev0) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (75.8.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pandas->datasets>=2.21.0->trl==0.15.0.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pandas->datasets>=2.21.0->trl==0.15.0.dev0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /anaconda/envs/sglang/lib/python3.12/site-packages (from pandas->datasets>=2.21.0->trl==0.15.0.dev0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /anaconda/envs/sglang/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl==0.15.0.dev0) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/sglang/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl==0.15.0.dev0) (3.0.2)\n",
            "Building wheels for collected packages: trl\n",
            "  Building wheel for trl (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for trl: filename=trl-0.15.0.dev0-py3-none-any.whl size=314513 sha256=c753e3b67e0a6e188690a00bcfc03c784634e3f6e66a19a01699e4b1614ba51c\n",
            "  Stored in directory: /home/olivia/.cache/pip/wheels/1f/46/e2/1d706f988ec4990b7054b69e1191b11d7f48a1b5304605bf21\n",
            "Successfully built trl\n",
            "Installing collected packages: trl\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.15.0\n",
            "    Uninstalling trl-0.15.0:\n",
            "      Successfully uninstalled trl-0.15.0\n",
            "Successfully installed trl-0.15.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install unsloth vllm\n",
        "!pip install --upgrade pillow\n",
        "!pip install diffusers\n",
        "# Temporarily install a specific TRL nightly version\n",
        "!pip install git+https://github.com/huggingface/trl.git@e95f9fb74a3c3647b86f251b7e230ec51c64b72b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZIDvOXePwBh"
      },
      "source": [
        "### install Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaBUw4wJ2WlP"
      },
      "source": [
        "ä½¿ç”¨PatchFastRLå¯¹HuggingFaceçš„trlè¿›è¡Œä¿®æ”¹ï¼Œæ³¨å…¥è‡ªå·±çš„åŠ é€Ÿä»£ç ã€‚ç›®å‰åªæ”¯æŒå•æœºç‰ˆçš„åŠ é€Ÿã€‚åˆ†å¸ƒå¼ç‰ˆå°šæœªæ”¯æŒã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59DIs5BMcvjN",
        "outputId": "5d03d8e6-d961-4101-8cd5-669944f91a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/sglang/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 02-26 07:17:24 __init__.py:190] Automatically detected platform cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-26 07:17:25,101\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel, PatchFastRL\n",
        "# Use `PatchFastRL` before all functions to patch GRPO and other RL algorithms!\n",
        "PatchFastRL(\"GRPO\", FastLanguageModel) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KROEggs82dUA"
      },
      "source": [
        "Load the phi-4 model and its tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805,
          "referenced_widgets": [
            "f57d844b2efa469e8aadd48175ce70ab",
            "47d2fd7f76754d9fa156576bc0c58abb",
            "81a0791760de4dcebd543c40d2c1e322",
            "a729c5fc5c764c85885cac7a2d4d95d0",
            "d6d5a7d96a034247b38d25d8a9cc979c",
            "4c9248100f89400d9e1407dbb168d5d6",
            "96cea0d773c8426b8be72dd7f72e5a82",
            "1b9f8a2a793640d689abc10f5f39c54b",
            "627f68389cf64e2a915a72ab147ee8a7",
            "9eed940f3815428583b4ddefc1a81469",
            "0b9230e976b34a9ea85978cf22857012",
            "22e0933485c14d94b0c1cfe198d6758f",
            "43462d5de24b4e55871b3f579798b374",
            "99577e7cbed74c89afb3d44d4fd956c5",
            "d034c840e7f74177a7b07a188d666b8d",
            "0f8ead1775934dc3a10533b67b3dd905",
            "e43ad27d5d304d1ebf9b374016409a97",
            "51948945111f437c9ed6ccab22072dd3",
            "4089236deafd4fa2be86d8dc0a29d469",
            "78cc90a50c0c4636b0f41436a820ecd3",
            "129dc789722b43439574390bba63b36a",
            "8991360910ef417db03499f76f5fe323"
          ]
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "c5a32856-2166-4485-fdb3-16241d0e6316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Switching from Unsloth dynamic quant to normal quant since\n",
            "we do not yet support fast inference for unsloth/phi-4-unsloth-bnb-4bit\n",
            "==((====))==  Unsloth 2025.2.12: Fast Llama patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    GPU: NVIDIA A100 80GB PCIe. Max memory: 79.151 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/phi-4-bnb-4bit with actual GPU utilization = 35.96%\n",
            "Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 79.15 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 512. Num Sequences = 288.\n",
            "Unsloth: vLLM's KV Cache can use up to 18.49 GB. Also swap space = 6 GB.\n",
            "INFO 02-26 07:18:11 config.py:542] This model supports multiple tasks: {'generate', 'reward', 'score', 'classify', 'embed'}. Defaulting to 'generate'.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection'], 'llm_int8_threshold': 6.0}\n",
            "INFO 02-26 07:18:12 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='unsloth/phi-4-bnb-4bit', speculative_config=None, tokenizer='unsloth/phi-4-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=512, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/phi-4-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":288}, use_cached_outputs=False, \n",
            "INFO 02-26 07:18:14 cuda.py:230] Using Flash Attention backend.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W226 07:18:14.952978546 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-26 07:18:14 model_runner.py:1110] Starting to load model unsloth/phi-4-bnb-4bit...\n",
            "INFO 02-26 07:18:16 loader.py:1102] Loading weights with BitsAndBytes quantization.  May take a while ...\n",
            "INFO 02-26 07:18:16 weight_utils.py:252] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:  50% Completed | 1/2 [02:54<02:54, 174.47s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [05:53<00:00, 177.23s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [05:53<00:00, 176.81s/it]\n",
            "\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:02<00:02,  2.64s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.08s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.02s/it]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-26 07:24:17 model_runner.py:1115] Loading model weights took 8.4920 GB\n",
            "INFO 02-26 07:24:17 punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 02-26 07:24:29 worker.py:267] Memory profiling takes 12.20 seconds\n",
            "INFO 02-26 07:24:29 worker.py:267] the current vLLM instance can use total_gpu_memory (79.15GiB) x gpu_memory_utilization (0.36) = 28.46GiB\n",
            "INFO 02-26 07:24:29 worker.py:267] model weights take 8.49GiB; non_torch_memory takes 13.01GiB; PyTorch activation peak memory takes 1.04GiB; the rest of the memory reserved for KV Cache is 5.92GiB.\n",
            "INFO 02-26 07:24:29 executor_base.py:110] # CUDA blocks: 1939, # CPU blocks: 1966\n",
            "INFO 02-26 07:24:29 executor_base.py:115] Maximum concurrency for 512 tokens per request: 60.59x\n",
            "INFO 02-26 07:24:35 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:41<00:00,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-26 07:25:17 model_runner.py:1562] Graph capturing finished in 41 secs, took 6.36 GiB\n",
            "INFO 02-26 07:25:17 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 60.18 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Not an error, but Unsloth cannot patch Attention layers with our manual autograd engine since either LoRA adapters\n",
            "are not enabled or a bias term (like in Qwen) is used.\n",
            "Not an error, but Unsloth cannot patch O projection layer with our manual autograd engine since either LoRA adapters\n",
            "are not enabled or a bias term (like in Qwen) is used.\n",
            "Unsloth 2025.2.12 patched 40 layers with 0 QKV layers, 0 O layers and 40 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import is_bfloat16_supported\n",
        "import torch\n",
        "max_seq_length = 512 # Can increase for longer reasoning traces\n",
        "lora_rank = 16 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"microsoft/phi-4\", # Load up `Phi-4 14B`, and set parameters\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.4, # Reduce if out of memory  #0.7\n",
        "    device_map='cuda:0',\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"gate_proj\", \"up_proj\", \"down_proj\",], #è¦å¾®è°ƒçš„æ¨¡å—ï¼ˆé»˜è®¤åŒ…æ‹¬ ï¼‰\n",
        "    lora_alpha = lora_rank,\n",
        "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSlkA49z2xZB"
      },
      "source": [
        "### å¥–åŠ±å‡½æ•°å®šä¹‰å’Œæ•°æ®å‡†å¤‡ \n",
        "<a name=\"Data\"></a\n",
        "\n",
        "å¯èƒ½éœ€è¦ç­‰å¾… 150 åˆ° 200 ä¸ªæ­¥éª¤å¥–åŠ±æ‰ä¼šçœŸæ­£å¢åŠ ã€‚ä¸ºäº†è·å¾—ä¸é”™çš„ç»“æœï¼Œæ‚¨å¯èƒ½éœ€è¦äº¤æ˜“è‡³å°‘ 12 å°æ—¶ï¼ˆè¿™å°±æ˜¯ GRPO çš„è¿ä½œæ–¹å¼ï¼‰ï¼Œè¿™ä¸æ˜¯å¼ºåˆ¶æ€§çš„ã€‚\n",
        "\n",
        "\n",
        "ä¸ºäº†è·å¾—æœ€ä½³ç»“æœï¼Œè‡³å°‘è¦æœ‰ 500 è¡Œæ•°æ®ã€‚å¯ä»¥å°è¯•ä½¿ç”¨ 10 è¡Œæ•°æ®ï¼Œä½†æœ€å¥½æœ‰æ›´å¤šæ•°æ®ã€‚\n",
        "\n",
        "\n",
        "æ¯æ¬¡è®­ç»ƒè¿è¡Œæ€»æ˜¯ä¸åŒçš„ï¼Œå…·ä½“å–å†³äºæ¨¡å‹ã€æ•°æ®ã€å¥–åŠ±å‡½æ•°/éªŒè¯å™¨ç­‰ã€‚\n",
        "\n",
        "\n",
        "ä¸ºäº†è¾¾åˆ°æ¼”ç¤ºæ•ˆæœï¼Œå‚è€ƒ [@willccbb](https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXk993X6C2ZZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Load and prep dataset\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "<reasoning>\n",
        "{reasoning}\n",
        "</reasoning>\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    # å°†è¾“å…¥çš„æ–‡æœ¬å­—ç¬¦ä¸²æŒ‰ç…§\"<answer>\"è¿›è¡Œåˆ†å‰²ï¼Œå¾—åˆ°ä¸€ä¸ªåˆ—è¡¨\n",
        "    # å–åˆ—è¡¨ä¸­çš„æœ€åä¸€ä¸ªå…ƒç´ ï¼Œå³åŒ…å«ç­”æ¡ˆçš„éƒ¨åˆ†\n",
        "    answer = text.split(\"<answer>\")[-1]\n",
        "    answer = answer.split(\"</answer>\")[0]\n",
        "    # ä½¿ç”¨strip()æ–¹æ³•å»é™¤ç­”æ¡ˆå­—ç¬¦ä¸²ä¸¤ç«¯çš„ç©ºç™½å­—ç¬¦ï¼ˆåŒ…æ‹¬ç©ºæ ¼ã€æ¢è¡Œç¬¦ç­‰ï¼‰\n",
        "    # è¿”å›å¤„ç†åçš„ç­”æ¡ˆå­—ç¬¦ä¸²\n",
        "    return answer.strip()\n",
        "\n",
        "def extract_hash_answer(text: str) -> str | None:\n",
        "    if \"####\" not in text:\n",
        "        return None\n",
        "    return text.split(\"####\")[1].strip()\n",
        "\n",
        "# uncomment middle messages for 1-shot prompting\n",
        "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
        "    # åŠ è½½GSM8Kæ•°æ®é›†ï¼ŒæŒ‡å®šsplitä¸º\"train\"æˆ–\"test\"\n",
        "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
        "    # ä½¿ç”¨mapå‡½æ•°å¯¹æ•°æ®é›†è¿›è¡Œè½¬æ¢ï¼Œå°†æ¯ä¸ªæ ·æœ¬çš„'question'å’Œ'answer'å­—æ®µè½¬æ¢ä¸ºç‰¹å®šæ ¼å¼\n",
        "    data = data.map(lambda x: { # type: ignore\n",
        "        'prompt': [ # æ„é€ å¯¹è¯æç¤ºï¼ŒåŒ…å«ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·é—®é¢˜\n",
        "            {'role': 'system', 'content': SYSTEM_PROMPT}, # ç³»ç»Ÿæç¤ºï¼Œé€šå¸¸åŒ…å«å¯¹è¯çš„èƒŒæ™¯ä¿¡æ¯æˆ–è§„åˆ™\n",
        "            {'role': 'user', 'content': x['question']} # ç”¨æˆ·é—®é¢˜ï¼Œä»åŸå§‹æ•°æ®ä¸­æå–\n",
        "        ],\n",
        "        'answer': extract_hash_answer(x['answer']) # æå–ç­”æ¡ˆçš„å“ˆå¸Œå€¼ï¼Œå…·ä½“å®ç°è§extract_hash_answerå‡½æ•°\n",
        "    }) # type: ignore\n",
        "    return data # type: ignore\n",
        "\n",
        "dataset = get_gsm8k_questions()\n",
        "\n",
        "\n",
        "############  å¥–åŠ±å‡½æ•° ############\n",
        "\n",
        "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    # ä»completionsåˆ—è¡¨ä¸­æå–æ¯ä¸ªå®Œæˆå†…å®¹çš„ç¬¬ä¸€ä¸ªå…ƒç´ çš„contentéƒ¨åˆ†\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    # ä»promptsåˆ—è¡¨ä¸­æå–æœ€åä¸€ä¸ªå…ƒç´ çš„contentéƒ¨åˆ†ï¼Œä½œä¸ºé—®é¢˜\n",
        "    q = prompts[0][-1]['content']\n",
        "    # å¯¹æ¯ä¸ªå“åº”å†…å®¹è°ƒç”¨extract_xml_answerå‡½æ•°ï¼Œæå–å‡ºç­”æ¡ˆéƒ¨åˆ†\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    # æ‰“å°åˆ†éš”çº¿ã€é—®é¢˜ã€æ ‡å‡†ç­”æ¡ˆã€ç¬¬ä¸€ä¸ªå“åº”å†…å®¹å’Œç¬¬ä¸€ä¸ªæå–çš„ç­”æ¡ˆ\n",
        "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
        "    # æ¯”è¾ƒæå–çš„ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆï¼Œå¦‚æœç›¸åŒåˆ™è¿”å›2.0ï¼Œå¦åˆ™è¿”å›0.0ï¼Œå½¢æˆåˆ—è¡¨è¿”å›\n",
        "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
        "\n",
        "def int_reward_func(completions, **kwargs) -> list[float]:\n",
        "    # ä»è¾“å…¥çš„completionsåˆ—è¡¨ä¸­æå–æ¯ä¸ªå®Œæˆé¡¹çš„ç¬¬ä¸€ä¸ªå†…å®¹çš„æ–‡æœ¬éƒ¨åˆ†\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    # å¯¹æ¯ä¸ªå“åº”æ–‡æœ¬è°ƒç”¨extract_xml_answerå‡½æ•°ï¼Œæå–å‡ºXMLæ ¼å¼çš„ç­”æ¡ˆ\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    # å¯¹æ¯ä¸ªæå–å‡ºçš„ç­”æ¡ˆè¿›è¡Œåˆ¤æ–­ï¼Œå¦‚æœæ˜¯æ•°å­—åˆ™è¿”å›0.5ï¼Œå¦åˆ™è¿”å›0.0\n",
        "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
        "\n",
        "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    # å®šä¹‰ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼Œç”¨äºåŒ¹é…ç‰¹å®šæ ¼å¼çš„å­—ç¬¦ä¸²\n",
        "    # è¯¥æ¨¡å¼è¦æ±‚å­—ç¬¦ä¸²ä»¥\"<reasoning>\"å¼€å§‹ï¼Œç„¶åæ˜¯ä»»æ„å­—ç¬¦ï¼Œæ¥ç€æ˜¯\"</reasoning>\"\n",
        "    # ç„¶åæ˜¯\"<answer>\"ï¼Œå†æ¥ç€æ˜¯ä»»æ„å­—ç¬¦ï¼Œæœ€åæ˜¯\"</answer>\"\n",
        "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
        "    # ä»è¾“å…¥çš„completionsåˆ—è¡¨ä¸­æå–æ¯ä¸ªå®Œæˆçš„å†…å®¹\n",
        "    # completionsæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå­—å…¸ä¸­åŒ…å«ä¸€ä¸ªé”®ä¸º\"content\"çš„é¡¹ï¼Œå…¶å€¼ä¸ºå®Œæˆçš„å†…å®¹\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼åŒ¹é…æ¯ä¸ªå“åº”å†…å®¹\n",
        "    # re.matchå‡½æ•°å°è¯•ä»å­—ç¬¦ä¸²çš„å¼€å§‹ä½ç½®åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼\n",
        "    # å¦‚æœåŒ¹é…æˆåŠŸï¼Œè¿”å›ä¸€ä¸ªåŒ¹é…å¯¹è±¡ï¼›å¦åˆ™è¿”å›None\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    # æ ¹æ®åŒ¹é…ç»“æœç”Ÿæˆå¥–åŠ±å€¼åˆ—è¡¨\n",
        "    # å¦‚æœåŒ¹é…æˆåŠŸï¼ˆmatchä¸ä¸ºNoneï¼‰ï¼Œåˆ™å¥–åŠ±å€¼ä¸º0.5ï¼›å¦åˆ™ä¸º0.0\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def count_xml(text) -> float:\n",
        "    count = 0.0\n",
        "    if text.count(\"<reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n<answer>\\n\") == 1:\n",
        "        count += 0.125\n",
        "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
        "    if text.count(\"\\n</answer>\") == 1:\n",
        "        count += 0.125\n",
        "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
        "    return count\n",
        "\n",
        "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
        "    contents = [completion[0][\"content\"] for completion in completions]\n",
        "    return [count_xml(c) for c in contents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tze5NF5523DB"
      },
      "source": [
        "### è®­ç»ƒæ¨¡å‹ Train the model\n",
        "\n",
        "å’Œç”¨Hugging faceçš„trlæ˜¯ä¸€æ ·çš„ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptqkXK2D4d6p",
        "outputId": "344b54e8-5a9c-4676-bfc0-23f8b5cb7426"
      },
      "outputs": [],
      "source": [
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    use_vllm = True, # use vLLM for fast inference!\n",
        "    learning_rate = 5e-5,#-6\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2 = 0.99,\n",
        "    weight_decay = 0.1,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    optim = \"paged_adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    bf16 = is_bfloat16_supported(),\n",
        "    fp16 = not is_bfloat16_supported(),\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 6, # Decrease if out of memory\n",
        "    max_prompt_length = 256,\n",
        "    max_completion_length = 200,\n",
        "    max_steps = 10,# 100\n",
        "    save_steps = 250,\n",
        "    max_grad_norm = 0.1,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "å‰ 100 ä¸ªæ­¥éª¤å¯èƒ½ä¼šè·å¾— 0 å¥–åŠ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vzOuSVCL_GA9",
        "outputId": "0fe20ec2-ea69-486a-e2df-4685bd390413"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 7,473 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 1\n",
            "\\        /    Total batch size = 1 | Total steps = 10\n",
            " \"-____-\"     Number of trainable parameters = 44,236,800\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------- Question:\n",
            "A concert ticket costs $40. Mr. Benson bought 12 tickets and received a 5% discount for every ticket bought that exceeds 10. How much did Mr. Benson pay in all? \n",
            "Answer:\n",
            "476 \n",
            "Response:\n",
            "<reasoning>\n",
            "To determine how much Mr. Benson paid, we need to calculate the cost of the first 10 tickets and then apply the discount for the remaining 2 tickets.\n",
            "\n",
            "1. **Calculate the cost of the first 10 tickets:**\n",
            "   - Each ticket costs $40.\n",
            "   - Therefore, the cost for 10 tickets is \\(10 \\times 40 = 400\\) dollars.\n",
            "\n",
            "2. **Calculate the cost of the additional 2 tickets with a discount:**\n",
            "   - Normally, each ticket costs $40.\n",
            "   - He receives a 5% discount for each ticket beyond the 10th.\n",
            "   - The discount per ticket is \\(5\\% \\times 40 = 0.05 \\times 40 = 2\\) dollars.\n",
            "   - Therefore, the discounted price per ticket is \\(40 - 2 = 38\\) dollars.\n",
            "   - The cost for 2 discounted tickets is \\(2 \\times 38 = 76\\) dollars.\n",
            "\n",
            " \n",
            "Extracted:\n",
            "<reasoning>\n",
            "To determine how much Mr. Benson paid, we need to calculate the cost of the first 10 tickets and then apply the discount for the remaining 2 tickets.\n",
            "\n",
            "1. **Calculate the cost of the first 10 tickets:**\n",
            "   - Each ticket costs $40.\n",
            "   - Therefore, the cost for 10 tickets is \\(10 \\times 40 = 400\\) dollars.\n",
            "\n",
            "2. **Calculate the cost of the additional 2 tickets with a discount:**\n",
            "   - Normally, each ticket costs $40.\n",
            "   - He receives a 5% discount for each ticket beyond the 10th.\n",
            "   - The discount per ticket is \\(5\\% \\times 40 = 0.05 \\times 40 = 2\\) dollars.\n",
            "   - Therefore, the discounted price per ticket is \\(40 - 2 = 38\\) dollars.\n",
            "   - The cost for 2 discounted tickets is \\(2 \\times 38 = 76\\) dollars.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 07:39, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completion_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / xmlcount_reward_func</th>\n",
              "      <th>rewards / soft_format_reward_func</th>\n",
              "      <th>rewards / strict_format_reward_func</th>\n",
              "      <th>rewards / int_reward_func</th>\n",
              "      <th>rewards / correctness_reward_func</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.064550</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.128500</td>\n",
              "      <td>0.147544</td>\n",
              "      <td>195.833344</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>-0.128500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.503000</td>\n",
              "      <td>0.925907</td>\n",
              "      <td>195.500000</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.086333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------- Question:\n",
            "Jane is trying to decide whether to buy a house or a trailer. A house costs $480,000 and a trailer costs $120,000. Each loan will be paid in monthly installments over 20 years. How much more is the monthly payment on the house compared to the trailer? \n",
            "Answer:\n",
            "1500 \n",
            "Response:\n",
            "<reasoning>\n",
            "To determine how much more the monthly payment on the house is compared to the trailer, we need to calculate the monthly loan payments for both the house and the trailer using the formula for monthly payments on an amortizing loan:\n",
            "\n",
            "\\[\n",
            "M = P \\frac{r(1 + r)^n}{(1 + r)^n - 1}\n",
            "\\]\n",
            "\n",
            "Where:\n",
            "- \\( M \\) is the monthly payment.\n",
            "- \\( P \\) is the principal loan amount (the initial amount of the loan).\n",
            "- \\( r \\) is the monthly interest rate (annual interest rate divided by 12).\n",
            "- \\( n \\) is the number of payments (loan term in years multiplied by 12).\n",
            "\n",
            "Assumptions:\n",
            "- For this problem, we have not been provided with an interest rate. In real-world scenarios, the interest rate significantly affects the monthly payment, so we will assume a hypothetical interest rate for this calculation. A common interest rate for mortgages and similar loans might \n",
            "Extracted:\n",
            "<reasoning>\n",
            "To determine how much more the monthly payment on the house is compared to the trailer, we need to calculate the monthly loan payments for both the house and the trailer using the formula for monthly payments on an amortizing loan:\n",
            "\n",
            "\\[\n",
            "M = P \\frac{r(1 + r)^n}{(1 + r)^n - 1}\n",
            "\\]\n",
            "\n",
            "Where:\n",
            "- \\( M \\) is the monthly payment.\n",
            "- \\( P \\) is the principal loan amount (the initial amount of the loan).\n",
            "- \\( r \\) is the monthly interest rate (annual interest rate divided by 12).\n",
            "- \\( n \\) is the number of payments (loan term in years multiplied by 12).\n",
            "\n",
            "Assumptions:\n",
            "- For this problem, we have not been provided with an interest rate. In real-world scenarios, the interest rate significantly affects the monthly payment, so we will assume a hypothetical interest rate for this calculation. A common interest rate for mortgages and similar loans might\n",
            "-------------------- Question:\n",
            "Janet pays $40/hour for 3 hours per week of clarinet lessons and $28/hour for 5 hours a week of piano lessons. How much more does she spend on piano lessons than clarinet lessons in a year? \n",
            "Answer:\n",
            "1040 \n",
            "Response:\n",
            "<reasoning>\n",
            "To determine how much more Janet spends on piano lessons than clarinet lessons in a year, we need to calculate the annual expense for each and then find the difference.\n",
            "\n",
            "1. **Clarinet Lessons:**\n",
            "   - Janet pays $40 per hour.\n",
            "   - She takes 3 hours per week.\n",
            "   - Weekly cost = $40/hour * 3 hours = $120.\n",
            "   - Yearly cost = $120/week * 52 weeks = $6,240.\n",
            "\n",
            "2. **Piano Lessons:**\n",
            "   - Janet pays $28 per hour.\n",
            "   - She takes 5 hours per week.\n",
            "   - Weekly cost = $28/hour * 5 hours = $140.\n",
            "   - Yearly cost = $140/week * 52 weeks = $7,280.\n",
            "\n",
            "3. **Difference:**\n",
            "   - Difference in yearly cost = Yearly cost of piano lessons - Yearly cost of clarinet lessons.\n",
            "   - Difference = $7, \n",
            "Extracted:\n",
            "<reasoning>\n",
            "To determine how much more Janet spends on piano lessons than clarinet lessons in a year, we need to calculate the annual expense for each and then find the difference.\n",
            "\n",
            "1. **Clarinet Lessons:**\n",
            "   - Janet pays $40 per hour.\n",
            "   - She takes 3 hours per week.\n",
            "   - Weekly cost = $40/hour * 3 hours = $120.\n",
            "   - Yearly cost = $120/week * 52 weeks = $6,240.\n",
            "\n",
            "2. **Piano Lessons:**\n",
            "   - Janet pays $28 per hour.\n",
            "   - She takes 5 hours per week.\n",
            "   - Weekly cost = $28/hour * 5 hours = $140.\n",
            "   - Yearly cost = $140/week * 52 weeks = $7,280.\n",
            "\n",
            "3. **Difference:**\n",
            "   - Difference in yearly cost = Yearly cost of piano lessons - Yearly cost of clarinet lessons.\n",
            "   - Difference = $7,\n",
            "-------------------- Question:\n",
            "Sabrina is collecting herbs to make a poultice for her grandmother. She needs twice as many basil leaves as sage leaves and 5 fewer sage leaves than verbena leaves. If she needs 12 basil leaves, how many leaves total does she need? \n",
            "Answer:\n",
            "29 \n",
            "Response:\n",
            "<reasoning>\n",
            "1. Let's start by defining the variables based on the problem statement:\n",
            "   - Let \\( b \\) be the number of basil leaves needed.\n",
            "   - Let \\( s \\) be the number of sage leaves needed.\n",
            "   - Let \\( v \\) be the number of verbena leaves needed.\n",
            "\n",
            "2. From the problem, we know:\n",
            "   - Sabrina needs twice as many basil leaves as sage leaves: \\( b = 2s \\).\n",
            "   - Sabrina needs 5 fewer sage leaves than verbena leaves: \\( s = v - 5 \\).\n",
            "\n",
            "3. We are given that Sabrina needs 12 basil leaves:\n",
            "   - \\( b = 12 \\).\n",
            "\n",
            "4. Substitute \\( b = 12 \\) into the equation \\( b = 2s \\):\n",
            "   - \\( 12 = 2s \\).\n",
            "   - Divide both sides by 2 to find \\( s \\): \\( s = 6 \\).\n",
            "\n",
            "5. Now that \n",
            "Extracted:\n",
            "<reasoning>\n",
            "1. Let's start by defining the variables based on the problem statement:\n",
            "   - Let \\( b \\) be the number of basil leaves needed.\n",
            "   - Let \\( s \\) be the number of sage leaves needed.\n",
            "   - Let \\( v \\) be the number of verbena leaves needed.\n",
            "\n",
            "2. From the problem, we know:\n",
            "   - Sabrina needs twice as many basil leaves as sage leaves: \\( b = 2s \\).\n",
            "   - Sabrina needs 5 fewer sage leaves than verbena leaves: \\( s = v - 5 \\).\n",
            "\n",
            "3. We are given that Sabrina needs 12 basil leaves:\n",
            "   - \\( b = 12 \\).\n",
            "\n",
            "4. Substitute \\( b = 12 \\) into the equation \\( b = 2s \\):\n",
            "   - \\( 12 = 2s \\).\n",
            "   - Divide both sides by 2 to find \\( s \\): \\( s = 6 \\).\n",
            "\n",
            "5. Now that\n",
            "-------------------- Question:\n",
            "Over the past five years, on July 4th, the high temperature for Washington, DC has been: 90 degrees in 2020, 90 degrees in 2019, 90 degrees in 2018, 79 degrees in 2017 and 71 degrees in 2016. What is the average temperature for July 4th in Washington, DC over the past 5 years? \n",
            "Answer:\n",
            "84 \n",
            "Response:\n",
            "<reasoning>\n",
            "To find the average temperature for July 4th over the past five years, we need to sum up all the recorded high temperatures for those years and then divide by the number of years.\n",
            "\n",
            "The recorded temperatures are:\n",
            "- 2020: 90 degrees\n",
            "- 2019: 90 degrees\n",
            "- 2018: 90 degrees\n",
            "- 2017: 79 degrees\n",
            "- 2016: 71 degrees\n",
            "\n",
            "First, add the temperatures together:\n",
            "\\[ 90 + 90 + 90 + 79 + 71 = 420 \\]\n",
            "\n",
            "Next, divide the total sum by the number of years (5 years):\n",
            "\\[ \\frac{420}{5} = 84 \\]\n",
            "\n",
            "Therefore, the average temperature for July 4th over the past five years is 84 degrees.\n",
            "</reasoning>\n",
            "\n",
            "<answer>\n",
            "The average temperature for July 4th in Washington, DC over the past 5 years is 84 degrees.\n",
            "</answer> \n",
            "Extracted:\n",
            "The average temperature for July 4th in Washington, DC over the past 5 years is 84 degrees.\n",
            "-------------------- Question:\n",
            "Rene can finish reading 30 pages in 60 minutes. Lulu can read 27 pages in 60 minutes and Cherry can read 25 pages in 60 minutes. If they have been reading for 240 minutes now, how many pages have they finished reading in total? \n",
            "Answer:\n",
            "328 \n",
            "Response:\n",
            "<reasoning>\n",
            "To find out how many pages Rene, Lulu, and Cherry have finished reading in total after 240 minutes, we first need to determine how many pages each person reads per minute and then calculate how many pages they read in 240 minutes.\n",
            "\n",
            "1. Rene reads 30 pages in 60 minutes. Therefore, Rene's reading rate is:\n",
            "   \\[\n",
            "   \\frac{30 \\text{ pages}}{60 \\text{ minutes}} = 0.5 \\text{ pages per minute}\n",
            "   \\]\n",
            "   In 240 minutes, Rene reads:\n",
            "   \\[\n",
            "   0.5 \\text{ pages/minute} \\times 240 \\text{ minutes} = 120 \\text{ pages}\n",
            "   \\]\n",
            "\n",
            "2. Lulu reads 27 pages in 60 minutes. Therefore, Lulu's reading rate is:\n",
            "   \\[\n",
            "   \\frac{27 \\text{ pages}}{60 \\text{ minutes}} = 0.45 \\ \n",
            "Extracted:\n",
            "<reasoning>\n",
            "To find out how many pages Rene, Lulu, and Cherry have finished reading in total after 240 minutes, we first need to determine how many pages each person reads per minute and then calculate how many pages they read in 240 minutes.\n",
            "\n",
            "1. Rene reads 30 pages in 60 minutes. Therefore, Rene's reading rate is:\n",
            "   \\[\n",
            "   \\frac{30 \\text{ pages}}{60 \\text{ minutes}} = 0.5 \\text{ pages per minute}\n",
            "   \\]\n",
            "   In 240 minutes, Rene reads:\n",
            "   \\[\n",
            "   0.5 \\text{ pages/minute} \\times 240 \\text{ minutes} = 120 \\text{ pages}\n",
            "   \\]\n",
            "\n",
            "2. Lulu reads 27 pages in 60 minutes. Therefore, Lulu's reading rate is:\n",
            "   \\[\n",
            "   \\frac{27 \\text{ pages}}{60 \\text{ minutes}} = 0.45 \\\n",
            "-------------------- Question:\n",
            "Martin rings the small bell 4 times more than 1/3 as often as the big bell. If he rings both of them a combined total of 52 times, how many times does he ring the big bell? \n",
            "Answer:\n",
            "36 \n",
            "Response:\n",
            "<reasoning>\n",
            "Let \\( x \\) represent the number of times Martin rings the big bell. According to the problem, Martin rings the small bell 4 times more than \\(\\frac{1}{3}\\) as often as the big bell. Thus, the number of times he rings the small bell can be expressed as:\n",
            "\n",
            "\\[ \\text{Small bell rings} = \\frac{1}{3}x + 4 \\]\n",
            "\n",
            "Since Martin rings both bells a combined total of 52 times, we can set up the following equation representing the total number of rings:\n",
            "\n",
            "\\[ x + \\left(\\frac{1}{3}x + 4\\right) = 52 \\]\n",
            "\n",
            "Simplifying the equation:\n",
            "\n",
            "\\[ x + \\frac{1}{3}x + 4 = 52 \\]\n",
            "\n",
            "Combine like terms:\n",
            "\n",
            "\\[ \\frac{3}{3}x + \\frac{1}{3}x = \\frac{4}{3}x \\]\n",
            "\n",
            "So the \n",
            "Extracted:\n",
            "<reasoning>\n",
            "Let \\( x \\) represent the number of times Martin rings the big bell. According to the problem, Martin rings the small bell 4 times more than \\(\\frac{1}{3}\\) as often as the big bell. Thus, the number of times he rings the small bell can be expressed as:\n",
            "\n",
            "\\[ \\text{Small bell rings} = \\frac{1}{3}x + 4 \\]\n",
            "\n",
            "Since Martin rings both bells a combined total of 52 times, we can set up the following equation representing the total number of rings:\n",
            "\n",
            "\\[ x + \\left(\\frac{1}{3}x + 4\\right) = 52 \\]\n",
            "\n",
            "Simplifying the equation:\n",
            "\n",
            "\\[ x + \\frac{1}{3}x + 4 = 52 \\]\n",
            "\n",
            "Combine like terms:\n",
            "\n",
            "\\[ \\frac{3}{3}x + \\frac{1}{3}x = \\frac{4}{3}x \\]\n",
            "\n",
            "So the\n",
            "-------------------- Question:\n",
            "Bert fills out the daily crossword puzzle in the newspaper every day. He uses up a pencil to fill out the puzzles every two weeks. On average, it takes him 1050 words to use up a pencil. How many words are in each crossword puzzle on average? \n",
            "Answer:\n",
            "75 \n",
            "Response:\n",
            "<reasoning>\n",
            "1. Begin by understanding the problem: Bert fills out a crossword puzzle every day and uses up a pencil every two weeks. \n",
            "\n",
            "2. Calculate the number of days in two weeks:  \n",
            "   \\[\n",
            "   2 \\text{ weeks} \\times 7 \\text{ days per week} = 14 \\text{ days}\n",
            "   \\]\n",
            "\n",
            "3. Bert fills in one crossword puzzle per day, so in 14 days, he fills out 14 crossword puzzles.\n",
            "\n",
            "4. It is given that 1050 words are written with one pencil that lasts 14 days. We need to find the average number of words written in each crossword puzzle.\n",
            "\n",
            "5. Calculate the average number of words per crossword puzzle by dividing the total number of words by the total number of puzzles filled in 14 days:\n",
            "   \\[\n",
            "   \\frac{1050 \\text{ words}}{14 \\text{ puzzles}} = 75 \\text{ words per puzzle}\n",
            "   \\]\n",
            "\n",
            " \n",
            "Extracted:\n",
            "<reasoning>\n",
            "1. Begin by understanding the problem: Bert fills out a crossword puzzle every day and uses up a pencil every two weeks. \n",
            "\n",
            "2. Calculate the number of days in two weeks:  \n",
            "   \\[\n",
            "   2 \\text{ weeks} \\times 7 \\text{ days per week} = 14 \\text{ days}\n",
            "   \\]\n",
            "\n",
            "3. Bert fills in one crossword puzzle per day, so in 14 days, he fills out 14 crossword puzzles.\n",
            "\n",
            "4. It is given that 1050 words are written with one pencil that lasts 14 days. We need to find the average number of words written in each crossword puzzle.\n",
            "\n",
            "5. Calculate the average number of words per crossword puzzle by dividing the total number of words by the total number of puzzles filled in 14 days:\n",
            "   \\[\n",
            "   \\frac{1050 \\text{ words}}{14 \\text{ puzzles}} = 75 \\text{ words per puzzle}\n",
            "   \\]\n",
            "-------------------- Question:\n",
            "Matt can make a batch of a dozen cookies using 2 pounds of flour.  He uses 4 bags of flour each weighing 5 pounds.  If Jim eats 15 cookies how many cookies are left? \n",
            "Answer:\n",
            "105 \n",
            "Response:\n",
            "<reasoning>\n",
            "1. First, determine how many pounds of flour Matt has:\n",
            "   - Each bag weighs 5 pounds, and he uses 4 bags.\n",
            "   - Total flour = 4 bags Ã— 5 pounds per bag = 20 pounds.\n",
            "\n",
            "2. Determine how many batches of cookies Matt can make with 20 pounds of flour:\n",
            "   - One batch (a dozen cookies) requires 2 pounds of flour.\n",
            "   - Number of batches = Total flour / Flour per batch = 20 pounds / 2 pounds per batch = 10 batches.\n",
            "\n",
            "3. Calculate the total number of cookies Matt can make:\n",
            "   - Each batch makes a dozen cookies = 12 cookies.\n",
            "   - Total cookies = Number of batches Ã— Cookies per batch = 10 batches Ã— 12 cookies per batch = 120 cookies.\n",
            "\n",
            "4. Determine how many cookies are left after Jim eats 15 cookies:\n",
            "   - Initial total cookies = 120 cookies.\n",
            "   - Cookies eaten by Jim = 15 cookies \n",
            "Extracted:\n",
            "<reasoning>\n",
            "1. First, determine how many pounds of flour Matt has:\n",
            "   - Each bag weighs 5 pounds, and he uses 4 bags.\n",
            "   - Total flour = 4 bags Ã— 5 pounds per bag = 20 pounds.\n",
            "\n",
            "2. Determine how many batches of cookies Matt can make with 20 pounds of flour:\n",
            "   - One batch (a dozen cookies) requires 2 pounds of flour.\n",
            "   - Number of batches = Total flour / Flour per batch = 20 pounds / 2 pounds per batch = 10 batches.\n",
            "\n",
            "3. Calculate the total number of cookies Matt can make:\n",
            "   - Each batch makes a dozen cookies = 12 cookies.\n",
            "   - Total cookies = Number of batches Ã— Cookies per batch = 10 batches Ã— 12 cookies per batch = 120 cookies.\n",
            "\n",
            "4. Determine how many cookies are left after Jim eats 15 cookies:\n",
            "   - Initial total cookies = 120 cookies.\n",
            "   - Cookies eaten by Jim = 15 cookies\n",
            "-------------------- Question:\n",
            "James decides to build a tin house by collecting 500 tins in a week. On the first day, he collects 50 tins. On the second day, he manages to collect 3 times that number. On the third day, he collects 50 tins fewer than the number he collected on the second day. If he collects an equal number of tins on the remaining days of the week, what's the number of tins he collected each day for the rest of the week? \n",
            "Answer:\n",
            "50 \n",
            "Response:\n",
            "<reasoning>\n",
            "To determine the number of tins James collects each day for the rest of the week, we first need to calculate how many tins he has collected in the first three days of the week.\n",
            "\n",
            "1. **Day 1:** James collects 50 tins.\n",
            "   \n",
            "2. **Day 2:** He collects 3 times the number of tins collected on Day 1. Therefore, he collects \\(3 \\times 50 = 150\\) tins.\n",
            "\n",
            "3. **Day 3:** He collects 50 tins fewer than the number he collected on Day 2. Thus, he collects \\(150 - 50 = 100\\) tins.\n",
            "\n",
            "Next, we calculate the total number of tins collected over the first three days:\n",
            "\\[50 \\, (\\text{Day 1}) + 150 \\, (\\text{Day 2}) + 100 \\, (\\text{Day 3}) = 300 \\, \\text{tins \n",
            "Extracted:\n",
            "<reasoning>\n",
            "To determine the number of tins James collects each day for the rest of the week, we first need to calculate how many tins he has collected in the first three days of the week.\n",
            "\n",
            "1. **Day 1:** James collects 50 tins.\n",
            "   \n",
            "2. **Day 2:** He collects 3 times the number of tins collected on Day 1. Therefore, he collects \\(3 \\times 50 = 150\\) tins.\n",
            "\n",
            "3. **Day 3:** He collects 50 tins fewer than the number he collected on Day 2. Thus, he collects \\(150 - 50 = 100\\) tins.\n",
            "\n",
            "Next, we calculate the total number of tins collected over the first three days:\n",
            "\\[50 \\, (\\text{Day 1}) + 150 \\, (\\text{Day 2}) + 100 \\, (\\text{Day 3}) = 300 \\, \\text{tins\n"
          ]
        }
      ],
      "source": [
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [ #ä»¥ä¸Šå®šä¹‰çš„å¤šä¸ªå¥–åŠ±å‡½æ•°\n",
        "        xmlcount_reward_func,\n",
        "        soft_format_reward_func,\n",
        "        strict_format_reward_func,\n",
        "        int_reward_func,\n",
        "        correctness_reward_func,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset\n",
        ")\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä»trainer_statså¯¹è±¡ä¸­è·å–è®­ç»ƒè¿‡ç¨‹ä¸­çš„åº¦é‡æŒ‡æ ‡\n",
        "metrics = trainer_stats.metrics\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'loss': 0.0,\n",
              "  'grad_norm': 0.0,\n",
              "  'learning_rate': 5e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 0.0,\n",
              "  'epoch': 0.00013381506757660912,\n",
              "  'step': 1},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 0.08599156886339188,\n",
              "  'learning_rate': 4.849231551964771e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.0833333358168602,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.0833333358168602,\n",
              "  'reward_std': 0.06454972922801971,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 0.0,\n",
              "  'epoch': 0.00026763013515321824,\n",
              "  'step': 2},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 6.406837928807363e-05,\n",
              "  'learning_rate': 4.415111107797445e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 8.270899706985801e-05,\n",
              "  'epoch': 0.0004014452027298274,\n",
              "  'step': 3},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 7.578793884022161e-05,\n",
              "  'learning_rate': 3.7500000000000003e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 9.515773126622662e-05,\n",
              "  'epoch': 0.0005352602703064365,\n",
              "  'step': 4},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 0.028311002999544144,\n",
              "  'learning_rate': 2.9341204441673266e-05,\n",
              "  'rewards/xmlcount_reward_func': -0.12850001454353333,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': -0.12850001454353333,\n",
              "  'reward_std': 0.1475435495376587,\n",
              "  'completion_length': 195.83334350585938,\n",
              "  'kl': 8.948562754085287e-05,\n",
              "  'epoch': 0.0006690753378830456,\n",
              "  'step': 5},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 5.4759453632868826e-05,\n",
              "  'learning_rate': 2.0658795558326743e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 7.954180182423443e-05,\n",
              "  'epoch': 0.0008028904054596548,\n",
              "  'step': 6},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 7.579489465570077e-05,\n",
              "  'learning_rate': 1.2500000000000006e-05,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 0.0001414473808836192,\n",
              "  'epoch': 0.0009367054730362638,\n",
              "  'step': 7},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 0.08122119307518005,\n",
              "  'learning_rate': 5.848888922025553e-06,\n",
              "  'rewards/xmlcount_reward_func': 0.08633333444595337,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0833333358168602,\n",
              "  'rewards/correctness_reward_func': 0.3333333432674408,\n",
              "  'reward': 0.503000020980835,\n",
              "  'reward_std': 0.9259072542190552,\n",
              "  'completion_length': 195.5,\n",
              "  'kl': 0.00022907111269887537,\n",
              "  'epoch': 0.001070520540612873,\n",
              "  'step': 8},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 5.362631782190874e-05,\n",
              "  'learning_rate': 1.5076844803522922e-06,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 0.00010956346523016691,\n",
              "  'epoch': 0.0012043356081894822,\n",
              "  'step': 9},\n",
              " {'loss': 0.0,\n",
              "  'grad_norm': 0.00012698340287897736,\n",
              "  'learning_rate': 0.0,\n",
              "  'rewards/xmlcount_reward_func': 0.125,\n",
              "  'rewards/soft_format_reward_func': 0.0,\n",
              "  'rewards/strict_format_reward_func': 0.0,\n",
              "  'rewards/int_reward_func': 0.0,\n",
              "  'rewards/correctness_reward_func': 0.0,\n",
              "  'reward': 0.125,\n",
              "  'reward_std': 0.0,\n",
              "  'completion_length': 200.0,\n",
              "  'kl': 0.0001731372030917555,\n",
              "  'epoch': 0.0013381506757660913,\n",
              "  'step': 10},\n",
              " {'train_runtime': 515.8447,\n",
              "  'train_samples_per_second': 0.019,\n",
              "  'train_steps_per_second': 0.019,\n",
              "  'total_flos': 0.0,\n",
              "  'train_loss': 3.99779188846594e-06,\n",
              "  'epoch': 0.0013381506757660913,\n",
              "  'step': 10}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.state.log_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbdvvDCbLrLe"
      },
      "source": [
        "### éƒ¨ç½²æ¨ç† Inference\n",
        "\n",
        "ä½¿ç”¨æ²¡GRPOè®­ç»ƒè¿‡çš„æ¨¡å‹è¿›è¡Œæ¨ç†çš„ä»£ç å¦‚ä¸‹:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "urQZvMTaLrrQ",
        "outputId": "b2ab3c22-cfd8-43b1-b173-4b780cd3fed0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.69s/it, est. speed input: 2.47 toks/s, output: 17.57 toks/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'100ä»¥å†…çš„è´¨æ•°æ˜¯åªæœ‰1å’Œè‡ªèº«ä¸¤ä¸ªæ­£æ•´æ•°å› å­çš„è‡ªç„¶æ•°ã€‚å®ƒä»¬æ˜¯ï¼š\\n\\n1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97\\n\\næ³¨æ„ï¼š1ä¸æ˜¯è´¨æ•°ï¼Œå®ƒé€šå¸¸è¢«æ’é™¤åœ¨è´¨æ•°çš„å®šä¹‰ä¹‹å¤–ã€‚'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"user\", \"content\" : \"100ä»¥å†…çš„è´¨æ•°æœ‰å“ªäº›?\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    [text],\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100ä»¥å†…çš„è´¨æ•°æ˜¯åªæœ‰1å’Œè‡ªèº«ä¸¤ä¸ªæ­£æ•´æ•°å› å­çš„è‡ªç„¶æ•°ã€‚å®ƒä»¬æ˜¯ï¼š\n",
            "\n",
            "1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97\n",
            "\n",
            "æ³¨æ„ï¼š1ä¸æ˜¯è´¨æ•°ï¼Œå®ƒé€šå¸¸è¢«æ’é™¤åœ¨è´¨æ•°çš„å®šä¹‰ä¹‹å¤–ã€‚\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXfSTmXFLyIE"
      },
      "source": [
        "ä¸ºäº†ä½¿ç”¨GRPOè®­ç»ƒåçš„æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦å…ˆä¿æŒè®­ç»ƒè¿‡çš„LoRAæƒé‡ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XOed9DauLydR"
      },
      "outputs": [],
      "source": [
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45U-8F0nL1Uf"
      },
      "source": [
        "ä½¿ç”¨GRPOè®­ç»ƒè¿‡çš„æ¨¡å‹è¿›è¡Œéƒ¨ç½²æ¨ç†:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "__w_7GamL1m1",
        "outputId": "2402a0e9-6ec0-4f65-9921-311888040df9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it, est. speed input: 1.66 toks/s, output: 15.03 toks/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'<reasoning>\\nè¦æ‰¾åˆ°100ä»¥å†…çš„è´¨æ•°ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦äº†è§£ä»€ä¹ˆæ˜¯è´¨æ•°ã€‚è´¨æ•°æ˜¯åªèƒ½è¢«1å’Œå®ƒæœ¬èº«æ•´é™¤çš„è‡ªç„¶æ•°ï¼Œä¸”ä¸ç­‰äº1ã€‚å› æ­¤ï¼Œè´¨æ•°å¿…é¡»å¤§äº1ã€‚\\n\\næˆ‘ä»¬ä»2å¼€å§‹ï¼Œå› ä¸º2æ˜¯æœ€å°çš„è´¨æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬é€ä¸ªæ£€æŸ¥æ¯ä¸ªæ•´æ•°æ˜¯å¦ç¬¦åˆè´¨æ•°çš„å®šä¹‰ï¼š\\n\\n- 2æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒåªèƒ½è¢«1å’Œ2æ•´é™¤ã€‚\\n- 3æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒåªèƒ½è¢«1å’Œ3æ•´é™¤ã€‚\\n- 4ä¸æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥è¢«2æ•´é™¤ã€‚\\n- 5æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒåªèƒ½è¢«1å’Œ5æ•´é™¤ã€‚\\n- 6ä¸æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥è¢«2å’Œ3æ•´é™¤ã€‚\\n- 7æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒåªèƒ½è¢«1å’Œ7æ•´é™¤ã€‚\\n- 8ä¸æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥è¢«2æ•´é™¤ã€‚\\n- 9ä¸æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥è¢«3æ•´é™¤ã€‚\\n- 10ä¸æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥è¢«2å’Œ5æ•´é™¤ã€‚\\n- 11æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒåªèƒ½è¢«1å’Œ11æ•´é™¤ã€‚\\n\\næˆ‘ä»¬ç»§ç»­è¿™ä¸ªè¿‡ç¨‹ï¼Œä¸€ç›´åˆ°100ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æ’é™¤æ‰€æœ‰éè´¨æ•°ï¼ˆåˆæ•°ï¼‰ï¼Œå³é‚£äº›èƒ½è¢«å°äºè‡ªèº«çš„è‡ªç„¶æ•°æ•´é™¤çš„æ•°ã€‚\\n\\nåœ¨è¿™ä¸ªèŒƒå›´å†…ï¼Œå¯ä»¥é€šè¿‡é™¤ä»¥å°äºå…¶å¹³æ–¹æ ¹çš„è´¨æ•°æ¥æµ‹è¯•ä¸€ä¸ªæ•°æ˜¯å¦ä¸ºè´¨æ•°ã€‚å¦‚æœä¸€ä¸ªæ•°ä¸èƒ½è¢«ä»»ä½•è¿™äº›è´¨æ•°æ•´é™¤ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯è´¨æ•°ã€‚\\n\\né€šè¿‡è¿™ä¸ªæ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥åˆ—å‡º100ä»¥å†…çš„è´¨æ•°ï¼š\\n2, 3, 5,'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
        "    {\"role\" : \"user\", \"content\" : \"100ä»¥å†…çš„è´¨æ•°æœ‰å“ªäº›?ç”¨ä¸­æ–‡å›ç­”\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP998x4tMRFE",
        "outputId": "13ea89c4-8b26-4ee7-9fec-9ed3441eaa53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<reasoning>\n",
            "è¦æ‰¾åˆ°100ä»¥å†…çš„è´¨æ•°ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦äº†è§£ä»€ä¹ˆæ˜¯è´¨æ•°ã€‚è´¨æ•°æ˜¯åªèƒ½è¢«1å’Œå®ƒæœ¬èº«æ•´é™¤çš„è‡ªç„¶æ•°ï¼Œä¸”ä¸ç­‰äº1ã€‚å› æ­¤ï¼Œè´¨æ•°å¿…é¡»å¤§äº1ã€‚\n",
            "\n",
            "æˆ‘ä»¬ä»2å¼€å§‹ï¼Œå› ä¸º2æ˜¯æœ€å°çš„è´¨æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬é€ä¸ªæ£€æŸ¥æ¯ä¸ªæ•´æ•°æ˜¯å¦ç¬¦åˆè´¨æ•°çš„å®šä¹‰ï¼š\n",
            "\n",
            "- 2æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒåªèƒ½è¢«1å’Œ2æ•´é™¤ã€‚\n",
            "- 3æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒåªèƒ½è¢«1å’Œ3æ•´é™¤ã€‚\n",
            "- 4ä¸æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥è¢«2æ•´é™¤ã€‚\n",
            "- 5æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒåªèƒ½è¢«1å’Œ5æ•´é™¤ã€‚\n",
            "- 6ä¸æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥è¢«2å’Œ3æ•´é™¤ã€‚\n",
            "- 7æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒåªèƒ½è¢«1å’Œ7æ•´é™¤ã€‚\n",
            "- 8ä¸æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥è¢«2æ•´é™¤ã€‚\n",
            "- 9ä¸æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥è¢«3æ•´é™¤ã€‚\n",
            "- 10ä¸æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒå¯ä»¥è¢«2å’Œ5æ•´é™¤ã€‚\n",
            "- 11æ˜¯è´¨æ•°ï¼Œå› ä¸ºå®ƒåªèƒ½è¢«1å’Œ11æ•´é™¤ã€‚\n",
            "\n",
            "æˆ‘ä»¬ç»§ç»­è¿™ä¸ªè¿‡ç¨‹ï¼Œä¸€ç›´åˆ°100ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æ’é™¤æ‰€æœ‰éè´¨æ•°ï¼ˆåˆæ•°ï¼‰ï¼Œå³é‚£äº›èƒ½è¢«å°äºè‡ªèº«çš„è‡ªç„¶æ•°æ•´é™¤çš„æ•°ã€‚\n",
            "\n",
            "åœ¨è¿™ä¸ªèŒƒå›´å†…ï¼Œå¯ä»¥é€šè¿‡é™¤ä»¥å°äºå…¶å¹³æ–¹æ ¹çš„è´¨æ•°æ¥æµ‹è¯•ä¸€ä¸ªæ•°æ˜¯å¦ä¸ºè´¨æ•°ã€‚å¦‚æœä¸€ä¸ªæ•°ä¸èƒ½è¢«ä»»ä½•è¿™äº›è´¨æ•°æ•´é™¤ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯è´¨æ•°ã€‚\n",
            "\n",
            "é€šè¿‡è¿™ä¸ªæ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥åˆ—å‡º100ä»¥å†…çš„è´¨æ•°ï¼š\n",
            "2, 3, 5,\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "sglang",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b9230e976b34a9ea85978cf22857012": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f8ead1775934dc3a10533b67b3dd905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "129dc789722b43439574390bba63b36a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b9f8a2a793640d689abc10f5f39c54b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e0933485c14d94b0c1cfe198d6758f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43462d5de24b4e55871b3f579798b374",
              "IPY_MODEL_99577e7cbed74c89afb3d44d4fd956c5",
              "IPY_MODEL_d034c840e7f74177a7b07a188d666b8d"
            ],
            "layout": "IPY_MODEL_0f8ead1775934dc3a10533b67b3dd905"
          }
        },
        "4089236deafd4fa2be86d8dc0a29d469": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43462d5de24b4e55871b3f579798b374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e43ad27d5d304d1ebf9b374016409a97",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_51948945111f437c9ed6ccab22072dd3",
            "value": ""
          }
        },
        "47d2fd7f76754d9fa156576bc0c58abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c9248100f89400d9e1407dbb168d5d6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_96cea0d773c8426b8be72dd7f72e5a82",
            "value": ""
          }
        },
        "4c9248100f89400d9e1407dbb168d5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51948945111f437c9ed6ccab22072dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "627f68389cf64e2a915a72ab147ee8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78cc90a50c0c4636b0f41436a820ecd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81a0791760de4dcebd543c40d2c1e322": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b9f8a2a793640d689abc10f5f39c54b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_627f68389cf64e2a915a72ab147ee8a7",
            "value": 2
          }
        },
        "8991360910ef417db03499f76f5fe323": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96cea0d773c8426b8be72dd7f72e5a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99577e7cbed74c89afb3d44d4fd956c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4089236deafd4fa2be86d8dc0a29d469",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78cc90a50c0c4636b0f41436a820ecd3",
            "value": 2
          }
        },
        "9eed940f3815428583b4ddefc1a81469": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a729c5fc5c764c85885cac7a2d4d95d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eed940f3815428583b4ddefc1a81469",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0b9230e976b34a9ea85978cf22857012",
            "value": "Loadingâ€‡safetensorsâ€‡checkpointâ€‡shards:â€‡100%â€‡Completedâ€‡|â€‡2/2â€‡[00:51&lt;00:00,â€‡25.46s/it]\n"
          }
        },
        "d034c840e7f74177a7b07a188d666b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_129dc789722b43439574390bba63b36a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8991360910ef417db03499f76f5fe323",
            "value": "Loadingâ€‡safetensorsâ€‡checkpointâ€‡shards:â€‡100%â€‡Completedâ€‡|â€‡2/2â€‡[00:47&lt;00:00,â€‡23.63s/it]\n"
          }
        },
        "d6d5a7d96a034247b38d25d8a9cc979c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e43ad27d5d304d1ebf9b374016409a97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f57d844b2efa469e8aadd48175ce70ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47d2fd7f76754d9fa156576bc0c58abb",
              "IPY_MODEL_81a0791760de4dcebd543c40d2c1e322",
              "IPY_MODEL_a729c5fc5c764c85885cac7a2d4d95d0"
            ],
            "layout": "IPY_MODEL_d6d5a7d96a034247b38d25d8a9cc979c"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
